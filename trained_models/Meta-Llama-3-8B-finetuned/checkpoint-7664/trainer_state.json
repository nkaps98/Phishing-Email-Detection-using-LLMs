{
  "best_global_step": 7600,
  "best_metric": 1.6197333335876465,
  "best_model_checkpoint": "trained_models/Meta-Llama-3-8B-finetuned/checkpoint-7600",
  "epoch": 2.0,
  "eval_steps": 200,
  "global_step": 7664,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026096033402922755,
      "grad_norm": 0.9473797678947449,
      "learning_rate": 2.6999999999999996e-05,
      "loss": 3.3,
      "step": 10
    },
    {
      "epoch": 0.005219206680584551,
      "grad_norm": 0.7902754545211792,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 3.2014,
      "step": 20
    },
    {
      "epoch": 0.007828810020876827,
      "grad_norm": 1.4978612661361694,
      "learning_rate": 8.699999999999999e-05,
      "loss": 3.1902,
      "step": 30
    },
    {
      "epoch": 0.010438413361169102,
      "grad_norm": 2.4808847904205322,
      "learning_rate": 0.000117,
      "loss": 2.7888,
      "step": 40
    },
    {
      "epoch": 0.013048016701461378,
      "grad_norm": 1.3473243713378906,
      "learning_rate": 0.000147,
      "loss": 2.794,
      "step": 50
    },
    {
      "epoch": 0.015657620041753653,
      "grad_norm": 2.1384294033050537,
      "learning_rate": 0.00017699999999999997,
      "loss": 2.6682,
      "step": 60
    },
    {
      "epoch": 0.01826722338204593,
      "grad_norm": 1.6469305753707886,
      "learning_rate": 0.00020699999999999996,
      "loss": 2.3852,
      "step": 70
    },
    {
      "epoch": 0.020876826722338204,
      "grad_norm": 1.6217899322509766,
      "learning_rate": 0.000237,
      "loss": 2.2335,
      "step": 80
    },
    {
      "epoch": 0.02348643006263048,
      "grad_norm": 1.6056658029556274,
      "learning_rate": 0.000267,
      "loss": 2.3298,
      "step": 90
    },
    {
      "epoch": 0.026096033402922755,
      "grad_norm": 1.4200365543365479,
      "learning_rate": 0.00029699999999999996,
      "loss": 2.4718,
      "step": 100
    },
    {
      "epoch": 0.02870563674321503,
      "grad_norm": 1.2103543281555176,
      "learning_rate": 0.00029964304600740344,
      "loss": 2.4347,
      "step": 110
    },
    {
      "epoch": 0.031315240083507306,
      "grad_norm": 1.4940903186798096,
      "learning_rate": 0.000299246430460074,
      "loss": 2.3793,
      "step": 120
    },
    {
      "epoch": 0.03392484342379958,
      "grad_norm": 2.7085986137390137,
      "learning_rate": 0.00029884981491274455,
      "loss": 2.2062,
      "step": 130
    },
    {
      "epoch": 0.03653444676409186,
      "grad_norm": 1.609557867050171,
      "learning_rate": 0.0002984531993654151,
      "loss": 2.3563,
      "step": 140
    },
    {
      "epoch": 0.03914405010438413,
      "grad_norm": NaN,
      "learning_rate": 0.0002980962453728186,
      "loss": 2.2899,
      "step": 150
    },
    {
      "epoch": 0.04175365344467641,
      "grad_norm": 1.6394881010055542,
      "learning_rate": 0.0002977392913802221,
      "loss": 2.3102,
      "step": 160
    },
    {
      "epoch": 0.044363256784968684,
      "grad_norm": 1.761124849319458,
      "learning_rate": 0.0002973426758328926,
      "loss": 2.2375,
      "step": 170
    },
    {
      "epoch": 0.04697286012526096,
      "grad_norm": 1.306486964225769,
      "learning_rate": 0.00029694606028556313,
      "loss": 2.3449,
      "step": 180
    },
    {
      "epoch": 0.049582463465553235,
      "grad_norm": 1.803901195526123,
      "learning_rate": 0.0002965494447382337,
      "loss": 2.4381,
      "step": 190
    },
    {
      "epoch": 0.05219206680584551,
      "grad_norm": 1.5241210460662842,
      "learning_rate": 0.00029615282919090425,
      "loss": 2.2153,
      "step": 200
    },
    {
      "epoch": 0.05219206680584551,
      "eval_loss": 2.142024517059326,
      "eval_runtime": 2.8315,
      "eval_samples_per_second": 42.381,
      "eval_steps_per_second": 5.298,
      "step": 200
    },
    {
      "epoch": 0.054801670146137786,
      "grad_norm": 1.4230464696884155,
      "learning_rate": 0.00029575621364357483,
      "loss": 2.2695,
      "step": 210
    },
    {
      "epoch": 0.05741127348643006,
      "grad_norm": 1.8558318614959717,
      "learning_rate": 0.00029535959809624536,
      "loss": 2.3516,
      "step": 220
    },
    {
      "epoch": 0.06002087682672234,
      "grad_norm": 1.2886179685592651,
      "learning_rate": 0.0002949629825489159,
      "loss": 2.401,
      "step": 230
    },
    {
      "epoch": 0.06263048016701461,
      "grad_norm": 1.5360989570617676,
      "learning_rate": 0.0002945663670015864,
      "loss": 2.1743,
      "step": 240
    },
    {
      "epoch": 0.0652400835073069,
      "grad_norm": 1.385305404663086,
      "learning_rate": 0.000294169751454257,
      "loss": 1.9764,
      "step": 250
    },
    {
      "epoch": 0.06784968684759916,
      "grad_norm": 2.7225921154022217,
      "learning_rate": 0.0002937731359069275,
      "loss": 2.2388,
      "step": 260
    },
    {
      "epoch": 0.07045929018789145,
      "grad_norm": 1.3701984882354736,
      "learning_rate": 0.00029337652035959805,
      "loss": 2.1901,
      "step": 270
    },
    {
      "epoch": 0.07306889352818371,
      "grad_norm": 1.4988847970962524,
      "learning_rate": 0.00029297990481226864,
      "loss": 2.2039,
      "step": 280
    },
    {
      "epoch": 0.075678496868476,
      "grad_norm": 1.2061203718185425,
      "learning_rate": 0.00029258328926493916,
      "loss": 2.2625,
      "step": 290
    },
    {
      "epoch": 0.07828810020876827,
      "grad_norm": 1.0339581966400146,
      "learning_rate": 0.0002921866737176097,
      "loss": 2.3071,
      "step": 300
    },
    {
      "epoch": 0.08089770354906055,
      "grad_norm": 1.4705777168273926,
      "learning_rate": 0.0002917900581702802,
      "loss": 2.1623,
      "step": 310
    },
    {
      "epoch": 0.08350730688935282,
      "grad_norm": 1.6919524669647217,
      "learning_rate": 0.0002913934426229508,
      "loss": 2.3158,
      "step": 320
    },
    {
      "epoch": 0.0861169102296451,
      "grad_norm": 1.451252818107605,
      "learning_rate": 0.00029099682707562133,
      "loss": 2.27,
      "step": 330
    },
    {
      "epoch": 0.08872651356993737,
      "grad_norm": 1.1245415210723877,
      "learning_rate": 0.0002906002115282919,
      "loss": 2.4417,
      "step": 340
    },
    {
      "epoch": 0.09133611691022965,
      "grad_norm": 1.3913440704345703,
      "learning_rate": 0.00029020359598096244,
      "loss": 2.1447,
      "step": 350
    },
    {
      "epoch": 0.09394572025052192,
      "grad_norm": 1.1855461597442627,
      "learning_rate": 0.00028980698043363297,
      "loss": 2.2062,
      "step": 360
    },
    {
      "epoch": 0.0965553235908142,
      "grad_norm": 1.398306965827942,
      "learning_rate": 0.0002894103648863035,
      "loss": 2.2558,
      "step": 370
    },
    {
      "epoch": 0.09916492693110647,
      "grad_norm": 1.119309902191162,
      "learning_rate": 0.0002890137493389741,
      "loss": 2.0709,
      "step": 380
    },
    {
      "epoch": 0.10177453027139875,
      "grad_norm": 1.2983109951019287,
      "learning_rate": 0.0002886171337916446,
      "loss": 2.1887,
      "step": 390
    },
    {
      "epoch": 0.10438413361169102,
      "grad_norm": 1.478358507156372,
      "learning_rate": 0.0002882205182443152,
      "loss": 2.242,
      "step": 400
    },
    {
      "epoch": 0.10438413361169102,
      "eval_loss": 2.067277193069458,
      "eval_runtime": 2.8427,
      "eval_samples_per_second": 42.214,
      "eval_steps_per_second": 5.277,
      "step": 400
    },
    {
      "epoch": 0.1069937369519833,
      "grad_norm": 1.3358224630355835,
      "learning_rate": 0.0002878239026969857,
      "loss": 2.0,
      "step": 410
    },
    {
      "epoch": 0.10960334029227557,
      "grad_norm": 1.4112110137939453,
      "learning_rate": 0.00028742728714965625,
      "loss": 2.2668,
      "step": 420
    },
    {
      "epoch": 0.11221294363256785,
      "grad_norm": 1.50267493724823,
      "learning_rate": 0.0002870306716023268,
      "loss": 2.0341,
      "step": 430
    },
    {
      "epoch": 0.11482254697286012,
      "grad_norm": 1.6485549211502075,
      "learning_rate": 0.0002866340560549973,
      "loss": 2.1729,
      "step": 440
    },
    {
      "epoch": 0.1174321503131524,
      "grad_norm": 1.5116333961486816,
      "learning_rate": 0.0002862374405076679,
      "loss": 2.004,
      "step": 450
    },
    {
      "epoch": 0.12004175365344467,
      "grad_norm": 1.0182571411132812,
      "learning_rate": 0.0002858408249603384,
      "loss": 2.232,
      "step": 460
    },
    {
      "epoch": 0.12265135699373696,
      "grad_norm": 1.929750919342041,
      "learning_rate": 0.00028544420941300895,
      "loss": 2.2361,
      "step": 470
    },
    {
      "epoch": 0.12526096033402923,
      "grad_norm": 1.2457783222198486,
      "learning_rate": 0.0002850475938656795,
      "loss": 2.1298,
      "step": 480
    },
    {
      "epoch": 0.1278705636743215,
      "grad_norm": 1.4609006643295288,
      "learning_rate": 0.00028465097831835006,
      "loss": 2.0982,
      "step": 490
    },
    {
      "epoch": 0.1304801670146138,
      "grad_norm": 1.3595210313796997,
      "learning_rate": 0.0002842543627710206,
      "loss": 2.0586,
      "step": 500
    },
    {
      "epoch": 0.13308977035490605,
      "grad_norm": 1.5333151817321777,
      "learning_rate": 0.00028385774722369117,
      "loss": 2.1025,
      "step": 510
    },
    {
      "epoch": 0.13569937369519833,
      "grad_norm": 1.4931272268295288,
      "learning_rate": 0.0002834611316763617,
      "loss": 2.1363,
      "step": 520
    },
    {
      "epoch": 0.1383089770354906,
      "grad_norm": 1.3140246868133545,
      "learning_rate": 0.0002830645161290322,
      "loss": 2.17,
      "step": 530
    },
    {
      "epoch": 0.1409185803757829,
      "grad_norm": 2.5902247428894043,
      "learning_rate": 0.00028266790058170275,
      "loss": 1.992,
      "step": 540
    },
    {
      "epoch": 0.14352818371607515,
      "grad_norm": 1.3278801441192627,
      "learning_rate": 0.0002822712850343733,
      "loss": 1.9968,
      "step": 550
    },
    {
      "epoch": 0.14613778705636743,
      "grad_norm": 1.55445396900177,
      "learning_rate": 0.00028187466948704387,
      "loss": 2.1601,
      "step": 560
    },
    {
      "epoch": 0.1487473903966597,
      "grad_norm": 1.7021571397781372,
      "learning_rate": 0.0002814780539397144,
      "loss": 2.0376,
      "step": 570
    },
    {
      "epoch": 0.151356993736952,
      "grad_norm": 1.2801263332366943,
      "learning_rate": 0.000281081438392385,
      "loss": 2.1246,
      "step": 580
    },
    {
      "epoch": 0.15396659707724425,
      "grad_norm": 1.741565227508545,
      "learning_rate": 0.0002806848228450555,
      "loss": 2.0602,
      "step": 590
    },
    {
      "epoch": 0.15657620041753653,
      "grad_norm": 1.5355188846588135,
      "learning_rate": 0.00028028820729772603,
      "loss": 2.1397,
      "step": 600
    },
    {
      "epoch": 0.15657620041753653,
      "eval_loss": 2.009150505065918,
      "eval_runtime": 2.8458,
      "eval_samples_per_second": 42.168,
      "eval_steps_per_second": 5.271,
      "step": 600
    },
    {
      "epoch": 0.15918580375782881,
      "grad_norm": 1.6424500942230225,
      "learning_rate": 0.00027989159175039656,
      "loss": 2.0036,
      "step": 610
    },
    {
      "epoch": 0.1617954070981211,
      "grad_norm": 1.2412208318710327,
      "learning_rate": 0.00027949497620306714,
      "loss": 2.1533,
      "step": 620
    },
    {
      "epoch": 0.16440501043841335,
      "grad_norm": 1.8316419124603271,
      "learning_rate": 0.00027909836065573767,
      "loss": 1.9212,
      "step": 630
    },
    {
      "epoch": 0.16701461377870563,
      "grad_norm": 1.3131541013717651,
      "learning_rate": 0.00027870174510840826,
      "loss": 2.069,
      "step": 640
    },
    {
      "epoch": 0.16962421711899792,
      "grad_norm": 1.2781678438186646,
      "learning_rate": 0.0002783051295610788,
      "loss": 2.0691,
      "step": 650
    },
    {
      "epoch": 0.1722338204592902,
      "grad_norm": 1.5722590684890747,
      "learning_rate": 0.0002779085140137493,
      "loss": 1.9494,
      "step": 660
    },
    {
      "epoch": 0.17484342379958245,
      "grad_norm": 1.1061371564865112,
      "learning_rate": 0.00027751189846641984,
      "loss": 2.0733,
      "step": 670
    },
    {
      "epoch": 0.17745302713987474,
      "grad_norm": 1.4372800588607788,
      "learning_rate": 0.0002771152829190904,
      "loss": 2.1397,
      "step": 680
    },
    {
      "epoch": 0.18006263048016702,
      "grad_norm": 1.2336269617080688,
      "learning_rate": 0.00027671866737176095,
      "loss": 2.4094,
      "step": 690
    },
    {
      "epoch": 0.1826722338204593,
      "grad_norm": 1.5031325817108154,
      "learning_rate": 0.0002763220518244315,
      "loss": 2.021,
      "step": 700
    },
    {
      "epoch": 0.18528183716075156,
      "grad_norm": 1.2982975244522095,
      "learning_rate": 0.00027592543627710206,
      "loss": 1.9994,
      "step": 710
    },
    {
      "epoch": 0.18789144050104384,
      "grad_norm": 1.2327343225479126,
      "learning_rate": 0.0002755288207297726,
      "loss": 2.0614,
      "step": 720
    },
    {
      "epoch": 0.19050104384133612,
      "grad_norm": 1.4970622062683105,
      "learning_rate": 0.0002751322051824431,
      "loss": 2.1894,
      "step": 730
    },
    {
      "epoch": 0.1931106471816284,
      "grad_norm": 1.555720329284668,
      "learning_rate": 0.00027473558963511365,
      "loss": 1.9803,
      "step": 740
    },
    {
      "epoch": 0.19572025052192066,
      "grad_norm": 1.4605212211608887,
      "learning_rate": 0.00027433897408778423,
      "loss": 2.0871,
      "step": 750
    },
    {
      "epoch": 0.19832985386221294,
      "grad_norm": 3.1994359493255615,
      "learning_rate": 0.00027394235854045476,
      "loss": 2.1423,
      "step": 760
    },
    {
      "epoch": 0.20093945720250522,
      "grad_norm": 2.0145864486694336,
      "learning_rate": 0.00027354574299312534,
      "loss": 2.0391,
      "step": 770
    },
    {
      "epoch": 0.2035490605427975,
      "grad_norm": 1.0472691059112549,
      "learning_rate": 0.00027314912744579587,
      "loss": 1.9567,
      "step": 780
    },
    {
      "epoch": 0.20615866388308976,
      "grad_norm": 1.3810325860977173,
      "learning_rate": 0.0002727525118984664,
      "loss": 1.749,
      "step": 790
    },
    {
      "epoch": 0.20876826722338204,
      "grad_norm": 1.5861594676971436,
      "learning_rate": 0.0002723558963511369,
      "loss": 2.2579,
      "step": 800
    },
    {
      "epoch": 0.20876826722338204,
      "eval_loss": 1.9597002267837524,
      "eval_runtime": 2.8472,
      "eval_samples_per_second": 42.147,
      "eval_steps_per_second": 5.268,
      "step": 800
    },
    {
      "epoch": 0.21137787056367432,
      "grad_norm": 1.8805686235427856,
      "learning_rate": 0.0002719592808038075,
      "loss": 2.0424,
      "step": 810
    },
    {
      "epoch": 0.2139874739039666,
      "grad_norm": 2.1002438068389893,
      "learning_rate": 0.00027156266525647804,
      "loss": 2.0281,
      "step": 820
    },
    {
      "epoch": 0.21659707724425886,
      "grad_norm": 1.2774308919906616,
      "learning_rate": 0.00027116604970914857,
      "loss": 2.1595,
      "step": 830
    },
    {
      "epoch": 0.21920668058455114,
      "grad_norm": 1.3206489086151123,
      "learning_rate": 0.0002707694341618191,
      "loss": 1.9851,
      "step": 840
    },
    {
      "epoch": 0.22181628392484343,
      "grad_norm": 1.2933663129806519,
      "learning_rate": 0.0002703728186144896,
      "loss": 2.2365,
      "step": 850
    },
    {
      "epoch": 0.2244258872651357,
      "grad_norm": 1.2083691358566284,
      "learning_rate": 0.0002699762030671602,
      "loss": 2.0979,
      "step": 860
    },
    {
      "epoch": 0.22703549060542796,
      "grad_norm": 1.5843946933746338,
      "learning_rate": 0.00026957958751983073,
      "loss": 2.1547,
      "step": 870
    },
    {
      "epoch": 0.22964509394572025,
      "grad_norm": 1.3819210529327393,
      "learning_rate": 0.0002691829719725013,
      "loss": 2.0611,
      "step": 880
    },
    {
      "epoch": 0.23225469728601253,
      "grad_norm": 1.4766513109207153,
      "learning_rate": 0.00026878635642517185,
      "loss": 2.1851,
      "step": 890
    },
    {
      "epoch": 0.2348643006263048,
      "grad_norm": 1.692933201789856,
      "learning_rate": 0.0002683897408778424,
      "loss": 2.0332,
      "step": 900
    },
    {
      "epoch": 0.23747390396659707,
      "grad_norm": 1.3914738893508911,
      "learning_rate": 0.0002679931253305129,
      "loss": 2.1793,
      "step": 910
    },
    {
      "epoch": 0.24008350730688935,
      "grad_norm": 1.6258418560028076,
      "learning_rate": 0.0002675965097831835,
      "loss": 1.9588,
      "step": 920
    },
    {
      "epoch": 0.24269311064718163,
      "grad_norm": 0.9674549102783203,
      "learning_rate": 0.000267199894235854,
      "loss": 2.036,
      "step": 930
    },
    {
      "epoch": 0.2453027139874739,
      "grad_norm": 1.2609611749649048,
      "learning_rate": 0.0002668032786885246,
      "loss": 2.108,
      "step": 940
    },
    {
      "epoch": 0.24791231732776617,
      "grad_norm": 1.5624159574508667,
      "learning_rate": 0.0002664066631411951,
      "loss": 1.9971,
      "step": 950
    },
    {
      "epoch": 0.25052192066805845,
      "grad_norm": 1.8039450645446777,
      "learning_rate": 0.00026601004759386565,
      "loss": 1.8347,
      "step": 960
    },
    {
      "epoch": 0.2531315240083507,
      "grad_norm": 1.611397624015808,
      "learning_rate": 0.0002656134320465362,
      "loss": 2.2125,
      "step": 970
    },
    {
      "epoch": 0.255741127348643,
      "grad_norm": 1.287266731262207,
      "learning_rate": 0.0002652168164992067,
      "loss": 1.9257,
      "step": 980
    },
    {
      "epoch": 0.25835073068893527,
      "grad_norm": 1.3283413648605347,
      "learning_rate": 0.0002648202009518773,
      "loss": 2.0223,
      "step": 990
    },
    {
      "epoch": 0.2609603340292276,
      "grad_norm": 1.035038948059082,
      "learning_rate": 0.0002644235854045478,
      "loss": 2.1573,
      "step": 1000
    },
    {
      "epoch": 0.2609603340292276,
      "eval_loss": 1.9354262351989746,
      "eval_runtime": 2.846,
      "eval_samples_per_second": 42.164,
      "eval_steps_per_second": 5.27,
      "step": 1000
    },
    {
      "epoch": 0.26356993736951984,
      "grad_norm": 1.4216818809509277,
      "learning_rate": 0.0002640269698572184,
      "loss": 2.0883,
      "step": 1010
    },
    {
      "epoch": 0.2661795407098121,
      "grad_norm": 1.597276210784912,
      "learning_rate": 0.00026363035430988893,
      "loss": 2.0256,
      "step": 1020
    },
    {
      "epoch": 0.2687891440501044,
      "grad_norm": 1.5374364852905273,
      "learning_rate": 0.00026323373876255946,
      "loss": 2.115,
      "step": 1030
    },
    {
      "epoch": 0.27139874739039666,
      "grad_norm": 1.5643314123153687,
      "learning_rate": 0.00026283712321523,
      "loss": 2.0139,
      "step": 1040
    },
    {
      "epoch": 0.2740083507306889,
      "grad_norm": 1.3334401845932007,
      "learning_rate": 0.00026244050766790057,
      "loss": 2.0809,
      "step": 1050
    },
    {
      "epoch": 0.2766179540709812,
      "grad_norm": 1.296218752861023,
      "learning_rate": 0.0002620438921205711,
      "loss": 2.1666,
      "step": 1060
    },
    {
      "epoch": 0.2792275574112735,
      "grad_norm": 1.705923080444336,
      "learning_rate": 0.0002616472765732417,
      "loss": 2.1091,
      "step": 1070
    },
    {
      "epoch": 0.2818371607515658,
      "grad_norm": 1.4831602573394775,
      "learning_rate": 0.0002612506610259122,
      "loss": 2.0061,
      "step": 1080
    },
    {
      "epoch": 0.28444676409185804,
      "grad_norm": 0.9169473648071289,
      "learning_rate": 0.00026085404547858274,
      "loss": 2.0624,
      "step": 1090
    },
    {
      "epoch": 0.2870563674321503,
      "grad_norm": 1.2049052715301514,
      "learning_rate": 0.00026045742993125327,
      "loss": 2.0361,
      "step": 1100
    },
    {
      "epoch": 0.2896659707724426,
      "grad_norm": 1.7434121370315552,
      "learning_rate": 0.00026006081438392385,
      "loss": 1.9328,
      "step": 1110
    },
    {
      "epoch": 0.29227557411273486,
      "grad_norm": 1.2413338422775269,
      "learning_rate": 0.0002596641988365944,
      "loss": 2.0214,
      "step": 1120
    },
    {
      "epoch": 0.2948851774530271,
      "grad_norm": 1.7803453207015991,
      "learning_rate": 0.0002592675832892649,
      "loss": 1.9805,
      "step": 1130
    },
    {
      "epoch": 0.2974947807933194,
      "grad_norm": 1.5455691814422607,
      "learning_rate": 0.0002588709677419355,
      "loss": 1.9911,
      "step": 1140
    },
    {
      "epoch": 0.3001043841336117,
      "grad_norm": 1.7623846530914307,
      "learning_rate": 0.000258474352194606,
      "loss": 1.9706,
      "step": 1150
    },
    {
      "epoch": 0.302713987473904,
      "grad_norm": 1.274327039718628,
      "learning_rate": 0.00025807773664727655,
      "loss": 2.0056,
      "step": 1160
    },
    {
      "epoch": 0.30532359081419624,
      "grad_norm": 1.203131914138794,
      "learning_rate": 0.0002576811210999471,
      "loss": 2.2323,
      "step": 1170
    },
    {
      "epoch": 0.3079331941544885,
      "grad_norm": 1.1240111589431763,
      "learning_rate": 0.00025728450555261766,
      "loss": 2.0981,
      "step": 1180
    },
    {
      "epoch": 0.3105427974947808,
      "grad_norm": 1.2565982341766357,
      "learning_rate": 0.0002568878900052882,
      "loss": 2.1442,
      "step": 1190
    },
    {
      "epoch": 0.31315240083507306,
      "grad_norm": 1.2988799810409546,
      "learning_rate": 0.0002564912744579587,
      "loss": 1.8667,
      "step": 1200
    },
    {
      "epoch": 0.31315240083507306,
      "eval_loss": 1.9044800996780396,
      "eval_runtime": 2.8437,
      "eval_samples_per_second": 42.198,
      "eval_steps_per_second": 5.275,
      "step": 1200
    },
    {
      "epoch": 0.3157620041753653,
      "grad_norm": 1.2520612478256226,
      "learning_rate": 0.00025609465891062924,
      "loss": 2.1045,
      "step": 1210
    },
    {
      "epoch": 0.31837160751565763,
      "grad_norm": 1.133244514465332,
      "learning_rate": 0.0002556980433632998,
      "loss": 2.1225,
      "step": 1220
    },
    {
      "epoch": 0.3209812108559499,
      "grad_norm": 1.8154714107513428,
      "learning_rate": 0.00025530142781597035,
      "loss": 1.8055,
      "step": 1230
    },
    {
      "epoch": 0.3235908141962422,
      "grad_norm": 1.0351824760437012,
      "learning_rate": 0.00025490481226864094,
      "loss": 1.7163,
      "step": 1240
    },
    {
      "epoch": 0.32620041753653445,
      "grad_norm": 1.2493418455123901,
      "learning_rate": 0.00025450819672131146,
      "loss": 2.1056,
      "step": 1250
    },
    {
      "epoch": 0.3288100208768267,
      "grad_norm": 1.5790765285491943,
      "learning_rate": 0.000254111581173982,
      "loss": 2.1457,
      "step": 1260
    },
    {
      "epoch": 0.331419624217119,
      "grad_norm": 1.2556908130645752,
      "learning_rate": 0.0002537149656266525,
      "loss": 2.0826,
      "step": 1270
    },
    {
      "epoch": 0.33402922755741127,
      "grad_norm": 1.6657333374023438,
      "learning_rate": 0.00025331835007932305,
      "loss": 2.1261,
      "step": 1280
    },
    {
      "epoch": 0.3366388308977035,
      "grad_norm": 1.3221979141235352,
      "learning_rate": 0.00025292173453199363,
      "loss": 2.2489,
      "step": 1290
    },
    {
      "epoch": 0.33924843423799583,
      "grad_norm": 1.9908987283706665,
      "learning_rate": 0.00025252511898466416,
      "loss": 1.9468,
      "step": 1300
    },
    {
      "epoch": 0.3418580375782881,
      "grad_norm": 1.5360454320907593,
      "learning_rate": 0.00025212850343733474,
      "loss": 1.9706,
      "step": 1310
    },
    {
      "epoch": 0.3444676409185804,
      "grad_norm": 1.4976561069488525,
      "learning_rate": 0.00025173188789000527,
      "loss": 1.975,
      "step": 1320
    },
    {
      "epoch": 0.34707724425887265,
      "grad_norm": 1.6375316381454468,
      "learning_rate": 0.0002513352723426758,
      "loss": 1.9646,
      "step": 1330
    },
    {
      "epoch": 0.3496868475991649,
      "grad_norm": 1.7161009311676025,
      "learning_rate": 0.00025093865679534633,
      "loss": 2.0262,
      "step": 1340
    },
    {
      "epoch": 0.3522964509394572,
      "grad_norm": 2.0916900634765625,
      "learning_rate": 0.0002505420412480169,
      "loss": 1.7723,
      "step": 1350
    },
    {
      "epoch": 0.35490605427974947,
      "grad_norm": 2.3397605419158936,
      "learning_rate": 0.00025014542570068744,
      "loss": 1.9365,
      "step": 1360
    },
    {
      "epoch": 0.3575156576200417,
      "grad_norm": 1.3305195569992065,
      "learning_rate": 0.000249748810153358,
      "loss": 2.0103,
      "step": 1370
    },
    {
      "epoch": 0.36012526096033404,
      "grad_norm": 1.4718658924102783,
      "learning_rate": 0.00024935219460602855,
      "loss": 1.7813,
      "step": 1380
    },
    {
      "epoch": 0.3627348643006263,
      "grad_norm": 1.5635737180709839,
      "learning_rate": 0.0002489555790586991,
      "loss": 2.0239,
      "step": 1390
    },
    {
      "epoch": 0.3653444676409186,
      "grad_norm": 1.5018508434295654,
      "learning_rate": 0.0002485589635113696,
      "loss": 1.9625,
      "step": 1400
    },
    {
      "epoch": 0.3653444676409186,
      "eval_loss": 1.891265630722046,
      "eval_runtime": 2.8477,
      "eval_samples_per_second": 42.14,
      "eval_steps_per_second": 5.267,
      "step": 1400
    },
    {
      "epoch": 0.36795407098121086,
      "grad_norm": 1.3500984907150269,
      "learning_rate": 0.00024816234796404014,
      "loss": 2.1568,
      "step": 1410
    },
    {
      "epoch": 0.3705636743215031,
      "grad_norm": 2.4815070629119873,
      "learning_rate": 0.0002477657324167107,
      "loss": 2.0155,
      "step": 1420
    },
    {
      "epoch": 0.3731732776617954,
      "grad_norm": 1.6752523183822632,
      "learning_rate": 0.00024736911686938125,
      "loss": 1.9313,
      "step": 1430
    },
    {
      "epoch": 0.3757828810020877,
      "grad_norm": 1.6308592557907104,
      "learning_rate": 0.00024697250132205183,
      "loss": 2.0542,
      "step": 1440
    },
    {
      "epoch": 0.37839248434237993,
      "grad_norm": 1.713914394378662,
      "learning_rate": 0.00024657588577472236,
      "loss": 1.9268,
      "step": 1450
    },
    {
      "epoch": 0.38100208768267224,
      "grad_norm": 1.1157147884368896,
      "learning_rate": 0.0002461792702273929,
      "loss": 2.1563,
      "step": 1460
    },
    {
      "epoch": 0.3836116910229645,
      "grad_norm": 1.3130435943603516,
      "learning_rate": 0.0002457826546800634,
      "loss": 2.0185,
      "step": 1470
    },
    {
      "epoch": 0.3862212943632568,
      "grad_norm": 1.718653678894043,
      "learning_rate": 0.000245386039132734,
      "loss": 2.1253,
      "step": 1480
    },
    {
      "epoch": 0.38883089770354906,
      "grad_norm": 1.643710732460022,
      "learning_rate": 0.0002449894235854045,
      "loss": 2.1884,
      "step": 1490
    },
    {
      "epoch": 0.3914405010438413,
      "grad_norm": 1.330816388130188,
      "learning_rate": 0.0002445928080380751,
      "loss": 2.15,
      "step": 1500
    },
    {
      "epoch": 0.3940501043841336,
      "grad_norm": 1.7000596523284912,
      "learning_rate": 0.00024419619249074564,
      "loss": 1.9542,
      "step": 1510
    },
    {
      "epoch": 0.3966597077244259,
      "grad_norm": 1.5117491483688354,
      "learning_rate": 0.00024379957694341617,
      "loss": 2.0411,
      "step": 1520
    },
    {
      "epoch": 0.39926931106471814,
      "grad_norm": 1.7867251634597778,
      "learning_rate": 0.0002434029613960867,
      "loss": 1.7743,
      "step": 1530
    },
    {
      "epoch": 0.40187891440501045,
      "grad_norm": 1.7945019006729126,
      "learning_rate": 0.00024300634584875722,
      "loss": 2.0784,
      "step": 1540
    },
    {
      "epoch": 0.4044885177453027,
      "grad_norm": 1.103933572769165,
      "learning_rate": 0.0002426097303014278,
      "loss": 1.9442,
      "step": 1550
    },
    {
      "epoch": 0.407098121085595,
      "grad_norm": 1.3238266706466675,
      "learning_rate": 0.00024221311475409833,
      "loss": 2.0446,
      "step": 1560
    },
    {
      "epoch": 0.40970772442588727,
      "grad_norm": 1.7332409620285034,
      "learning_rate": 0.0002418164992067689,
      "loss": 1.9804,
      "step": 1570
    },
    {
      "epoch": 0.4123173277661795,
      "grad_norm": 1.6050117015838623,
      "learning_rate": 0.00024141988365943942,
      "loss": 1.9442,
      "step": 1580
    },
    {
      "epoch": 0.41492693110647183,
      "grad_norm": 1.284942388534546,
      "learning_rate": 0.00024102326811210997,
      "loss": 2.1356,
      "step": 1590
    },
    {
      "epoch": 0.4175365344467641,
      "grad_norm": 1.2380119562149048,
      "learning_rate": 0.0002406266525647805,
      "loss": 2.0425,
      "step": 1600
    },
    {
      "epoch": 0.4175365344467641,
      "eval_loss": 1.8704352378845215,
      "eval_runtime": 2.8471,
      "eval_samples_per_second": 42.148,
      "eval_steps_per_second": 5.268,
      "step": 1600
    },
    {
      "epoch": 0.4201461377870564,
      "grad_norm": 1.5348987579345703,
      "learning_rate": 0.00024023003701745108,
      "loss": 1.8658,
      "step": 1610
    },
    {
      "epoch": 0.42275574112734865,
      "grad_norm": 1.5638607740402222,
      "learning_rate": 0.0002398334214701216,
      "loss": 1.9383,
      "step": 1620
    },
    {
      "epoch": 0.4253653444676409,
      "grad_norm": 1.7012673616409302,
      "learning_rate": 0.00023943680592279217,
      "loss": 2.2031,
      "step": 1630
    },
    {
      "epoch": 0.4279749478079332,
      "grad_norm": 2.0495259761810303,
      "learning_rate": 0.0002390401903754627,
      "loss": 2.1792,
      "step": 1640
    },
    {
      "epoch": 0.43058455114822547,
      "grad_norm": 1.1250945329666138,
      "learning_rate": 0.00023864357482813325,
      "loss": 2.0526,
      "step": 1650
    },
    {
      "epoch": 0.4331941544885177,
      "grad_norm": 1.8163994550704956,
      "learning_rate": 0.00023824695928080378,
      "loss": 2.0025,
      "step": 1660
    },
    {
      "epoch": 0.43580375782881003,
      "grad_norm": 1.3850146532058716,
      "learning_rate": 0.00023785034373347434,
      "loss": 1.7274,
      "step": 1670
    },
    {
      "epoch": 0.4384133611691023,
      "grad_norm": 1.5661041736602783,
      "learning_rate": 0.00023745372818614486,
      "loss": 2.0496,
      "step": 1680
    },
    {
      "epoch": 0.4410229645093946,
      "grad_norm": 1.4738582372665405,
      "learning_rate": 0.0002370571126388154,
      "loss": 1.8937,
      "step": 1690
    },
    {
      "epoch": 0.44363256784968685,
      "grad_norm": 1.7272379398345947,
      "learning_rate": 0.00023666049709148598,
      "loss": 1.9477,
      "step": 1700
    },
    {
      "epoch": 0.4462421711899791,
      "grad_norm": 2.070690155029297,
      "learning_rate": 0.0002362638815441565,
      "loss": 1.8385,
      "step": 1710
    },
    {
      "epoch": 0.4488517745302714,
      "grad_norm": 1.136544108390808,
      "learning_rate": 0.00023586726599682706,
      "loss": 1.9377,
      "step": 1720
    },
    {
      "epoch": 0.4514613778705637,
      "grad_norm": 1.167293667793274,
      "learning_rate": 0.0002354706504494976,
      "loss": 1.8363,
      "step": 1730
    },
    {
      "epoch": 0.45407098121085593,
      "grad_norm": 1.2836484909057617,
      "learning_rate": 0.00023507403490216814,
      "loss": 2.114,
      "step": 1740
    },
    {
      "epoch": 0.45668058455114824,
      "grad_norm": 1.120000958442688,
      "learning_rate": 0.00023467741935483867,
      "loss": 2.2061,
      "step": 1750
    },
    {
      "epoch": 0.4592901878914405,
      "grad_norm": 1.5560340881347656,
      "learning_rate": 0.00023428080380750925,
      "loss": 2.0623,
      "step": 1760
    },
    {
      "epoch": 0.4618997912317328,
      "grad_norm": 1.2890723943710327,
      "learning_rate": 0.00023388418826017978,
      "loss": 2.068,
      "step": 1770
    },
    {
      "epoch": 0.46450939457202506,
      "grad_norm": 1.45327889919281,
      "learning_rate": 0.00023348757271285034,
      "loss": 1.9195,
      "step": 1780
    },
    {
      "epoch": 0.4671189979123173,
      "grad_norm": 1.1536998748779297,
      "learning_rate": 0.00023309095716552087,
      "loss": 2.0418,
      "step": 1790
    },
    {
      "epoch": 0.4697286012526096,
      "grad_norm": 1.2719486951828003,
      "learning_rate": 0.00023269434161819142,
      "loss": 1.814,
      "step": 1800
    },
    {
      "epoch": 0.4697286012526096,
      "eval_loss": 1.850287914276123,
      "eval_runtime": 2.8441,
      "eval_samples_per_second": 42.192,
      "eval_steps_per_second": 5.274,
      "step": 1800
    },
    {
      "epoch": 0.4723382045929019,
      "grad_norm": 1.870507001876831,
      "learning_rate": 0.00023229772607086195,
      "loss": 1.8382,
      "step": 1810
    },
    {
      "epoch": 0.47494780793319413,
      "grad_norm": 1.3376216888427734,
      "learning_rate": 0.0002319011105235325,
      "loss": 1.8506,
      "step": 1820
    },
    {
      "epoch": 0.47755741127348644,
      "grad_norm": 1.633563756942749,
      "learning_rate": 0.00023150449497620303,
      "loss": 2.0908,
      "step": 1830
    },
    {
      "epoch": 0.4801670146137787,
      "grad_norm": 1.650639533996582,
      "learning_rate": 0.00023110787942887356,
      "loss": 2.0623,
      "step": 1840
    },
    {
      "epoch": 0.482776617954071,
      "grad_norm": 1.6068546772003174,
      "learning_rate": 0.00023071126388154415,
      "loss": 1.9331,
      "step": 1850
    },
    {
      "epoch": 0.48538622129436326,
      "grad_norm": 1.3056987524032593,
      "learning_rate": 0.00023031464833421467,
      "loss": 1.9,
      "step": 1860
    },
    {
      "epoch": 0.4879958246346555,
      "grad_norm": 1.2022175788879395,
      "learning_rate": 0.00022991803278688523,
      "loss": 1.8768,
      "step": 1870
    },
    {
      "epoch": 0.4906054279749478,
      "grad_norm": 1.4639533758163452,
      "learning_rate": 0.00022952141723955576,
      "loss": 2.1045,
      "step": 1880
    },
    {
      "epoch": 0.4932150313152401,
      "grad_norm": 1.1943522691726685,
      "learning_rate": 0.00022912480169222631,
      "loss": 1.924,
      "step": 1890
    },
    {
      "epoch": 0.49582463465553234,
      "grad_norm": 1.7867108583450317,
      "learning_rate": 0.00022872818614489684,
      "loss": 1.964,
      "step": 1900
    },
    {
      "epoch": 0.49843423799582465,
      "grad_norm": 1.5834448337554932,
      "learning_rate": 0.00022833157059756742,
      "loss": 1.9354,
      "step": 1910
    },
    {
      "epoch": 0.5010438413361169,
      "grad_norm": 1.6852755546569824,
      "learning_rate": 0.00022793495505023795,
      "loss": 1.9213,
      "step": 1920
    },
    {
      "epoch": 0.5036534446764092,
      "grad_norm": 1.0672882795333862,
      "learning_rate": 0.0002275383395029085,
      "loss": 2.0432,
      "step": 1930
    },
    {
      "epoch": 0.5062630480167014,
      "grad_norm": 1.406591773033142,
      "learning_rate": 0.00022714172395557904,
      "loss": 1.8395,
      "step": 1940
    },
    {
      "epoch": 0.5088726513569938,
      "grad_norm": 1.5374641418457031,
      "learning_rate": 0.0002267451084082496,
      "loss": 1.8151,
      "step": 1950
    },
    {
      "epoch": 0.511482254697286,
      "grad_norm": 1.6096782684326172,
      "learning_rate": 0.00022634849286092012,
      "loss": 1.8826,
      "step": 1960
    },
    {
      "epoch": 0.5140918580375783,
      "grad_norm": 1.5475019216537476,
      "learning_rate": 0.00022595187731359065,
      "loss": 2.0466,
      "step": 1970
    },
    {
      "epoch": 0.5167014613778705,
      "grad_norm": 1.5496262311935425,
      "learning_rate": 0.00022555526176626123,
      "loss": 2.0411,
      "step": 1980
    },
    {
      "epoch": 0.5193110647181628,
      "grad_norm": 2.0415754318237305,
      "learning_rate": 0.00022515864621893176,
      "loss": 2.0589,
      "step": 1990
    },
    {
      "epoch": 0.5219206680584552,
      "grad_norm": 1.5903455018997192,
      "learning_rate": 0.00022476203067160232,
      "loss": 2.1471,
      "step": 2000
    },
    {
      "epoch": 0.5219206680584552,
      "eval_loss": 1.839537262916565,
      "eval_runtime": 2.8496,
      "eval_samples_per_second": 42.11,
      "eval_steps_per_second": 5.264,
      "step": 2000
    },
    {
      "epoch": 0.5245302713987474,
      "grad_norm": 1.649817705154419,
      "learning_rate": 0.00022436541512427284,
      "loss": 2.1034,
      "step": 2010
    },
    {
      "epoch": 0.5271398747390397,
      "grad_norm": 1.3747363090515137,
      "learning_rate": 0.0002239687995769434,
      "loss": 1.7686,
      "step": 2020
    },
    {
      "epoch": 0.5297494780793319,
      "grad_norm": 1.2432899475097656,
      "learning_rate": 0.00022357218402961393,
      "loss": 1.7558,
      "step": 2030
    },
    {
      "epoch": 0.5323590814196242,
      "grad_norm": 1.5790379047393799,
      "learning_rate": 0.00022317556848228448,
      "loss": 2.1033,
      "step": 2040
    },
    {
      "epoch": 0.5349686847599165,
      "grad_norm": 1.3989677429199219,
      "learning_rate": 0.000222778952934955,
      "loss": 1.8179,
      "step": 2050
    },
    {
      "epoch": 0.5375782881002088,
      "grad_norm": 1.429231882095337,
      "learning_rate": 0.0002223823373876256,
      "loss": 1.7943,
      "step": 2060
    },
    {
      "epoch": 0.5401878914405011,
      "grad_norm": 1.0929794311523438,
      "learning_rate": 0.00022198572184029612,
      "loss": 1.8959,
      "step": 2070
    },
    {
      "epoch": 0.5427974947807933,
      "grad_norm": 1.444875955581665,
      "learning_rate": 0.00022158910629296668,
      "loss": 1.9946,
      "step": 2080
    },
    {
      "epoch": 0.5454070981210856,
      "grad_norm": 1.3802145719528198,
      "learning_rate": 0.0002211924907456372,
      "loss": 1.9604,
      "step": 2090
    },
    {
      "epoch": 0.5480167014613778,
      "grad_norm": 1.3936699628829956,
      "learning_rate": 0.00022079587519830776,
      "loss": 1.8285,
      "step": 2100
    },
    {
      "epoch": 0.5506263048016702,
      "grad_norm": 2.030755043029785,
      "learning_rate": 0.0002203992596509783,
      "loss": 2.0263,
      "step": 2110
    },
    {
      "epoch": 0.5532359081419624,
      "grad_norm": 1.6191338300704956,
      "learning_rate": 0.00022000264410364882,
      "loss": 1.7332,
      "step": 2120
    },
    {
      "epoch": 0.5558455114822547,
      "grad_norm": 1.7430469989776611,
      "learning_rate": 0.0002196060285563194,
      "loss": 1.9653,
      "step": 2130
    },
    {
      "epoch": 0.558455114822547,
      "grad_norm": 1.4878565073013306,
      "learning_rate": 0.00021920941300898993,
      "loss": 1.9765,
      "step": 2140
    },
    {
      "epoch": 0.5610647181628392,
      "grad_norm": 1.4366521835327148,
      "learning_rate": 0.0002188127974616605,
      "loss": 2.1343,
      "step": 2150
    },
    {
      "epoch": 0.5636743215031316,
      "grad_norm": 1.281952977180481,
      "learning_rate": 0.00021841618191433102,
      "loss": 2.0288,
      "step": 2160
    },
    {
      "epoch": 0.5662839248434238,
      "grad_norm": 1.695026159286499,
      "learning_rate": 0.00021801956636700157,
      "loss": 2.1795,
      "step": 2170
    },
    {
      "epoch": 0.5688935281837161,
      "grad_norm": 1.3461941480636597,
      "learning_rate": 0.0002176229508196721,
      "loss": 1.8978,
      "step": 2180
    },
    {
      "epoch": 0.5715031315240083,
      "grad_norm": 2.0981054306030273,
      "learning_rate": 0.00021722633527234265,
      "loss": 1.9091,
      "step": 2190
    },
    {
      "epoch": 0.5741127348643006,
      "grad_norm": 1.9086592197418213,
      "learning_rate": 0.00021682971972501318,
      "loss": 2.0341,
      "step": 2200
    },
    {
      "epoch": 0.5741127348643006,
      "eval_loss": 1.8177262544631958,
      "eval_runtime": 2.8511,
      "eval_samples_per_second": 42.089,
      "eval_steps_per_second": 5.261,
      "step": 2200
    },
    {
      "epoch": 0.576722338204593,
      "grad_norm": 1.3045437335968018,
      "learning_rate": 0.00021643310417768377,
      "loss": 1.977,
      "step": 2210
    },
    {
      "epoch": 0.5793319415448852,
      "grad_norm": 1.5796412229537964,
      "learning_rate": 0.0002160364886303543,
      "loss": 2.0794,
      "step": 2220
    },
    {
      "epoch": 0.5819415448851775,
      "grad_norm": 1.3529088497161865,
      "learning_rate": 0.00021563987308302485,
      "loss": 1.7494,
      "step": 2230
    },
    {
      "epoch": 0.5845511482254697,
      "grad_norm": 1.5535320043563843,
      "learning_rate": 0.00021524325753569538,
      "loss": 1.7956,
      "step": 2240
    },
    {
      "epoch": 0.587160751565762,
      "grad_norm": 1.5616564750671387,
      "learning_rate": 0.0002148466419883659,
      "loss": 2.0007,
      "step": 2250
    },
    {
      "epoch": 0.5897703549060542,
      "grad_norm": 1.231880784034729,
      "learning_rate": 0.00021445002644103646,
      "loss": 1.9049,
      "step": 2260
    },
    {
      "epoch": 0.5923799582463466,
      "grad_norm": 1.564984917640686,
      "learning_rate": 0.000214053410893707,
      "loss": 1.9645,
      "step": 2270
    },
    {
      "epoch": 0.5949895615866388,
      "grad_norm": 1.2050964832305908,
      "learning_rate": 0.00021365679534637757,
      "loss": 1.9339,
      "step": 2280
    },
    {
      "epoch": 0.5975991649269311,
      "grad_norm": 1.348548173904419,
      "learning_rate": 0.0002132601797990481,
      "loss": 1.8704,
      "step": 2290
    },
    {
      "epoch": 0.6002087682672234,
      "grad_norm": 1.572061538696289,
      "learning_rate": 0.00021286356425171866,
      "loss": 1.8382,
      "step": 2300
    },
    {
      "epoch": 0.6028183716075156,
      "grad_norm": 1.8961124420166016,
      "learning_rate": 0.00021246694870438919,
      "loss": 1.9224,
      "step": 2310
    },
    {
      "epoch": 0.605427974947808,
      "grad_norm": 1.6620901823043823,
      "learning_rate": 0.00021207033315705974,
      "loss": 1.8899,
      "step": 2320
    },
    {
      "epoch": 0.6080375782881002,
      "grad_norm": 1.5588363409042358,
      "learning_rate": 0.00021167371760973027,
      "loss": 1.9376,
      "step": 2330
    },
    {
      "epoch": 0.6106471816283925,
      "grad_norm": 1.1760387420654297,
      "learning_rate": 0.00021127710206240082,
      "loss": 1.9468,
      "step": 2340
    },
    {
      "epoch": 0.6132567849686847,
      "grad_norm": 1.4658652544021606,
      "learning_rate": 0.00021088048651507138,
      "loss": 1.9151,
      "step": 2350
    },
    {
      "epoch": 0.615866388308977,
      "grad_norm": 1.5487220287322998,
      "learning_rate": 0.00021048387096774194,
      "loss": 1.9511,
      "step": 2360
    },
    {
      "epoch": 0.6184759916492694,
      "grad_norm": 1.421868920326233,
      "learning_rate": 0.00021008725542041246,
      "loss": 1.9357,
      "step": 2370
    },
    {
      "epoch": 0.6210855949895616,
      "grad_norm": 1.1961393356323242,
      "learning_rate": 0.00020969063987308302,
      "loss": 1.8683,
      "step": 2380
    },
    {
      "epoch": 0.6236951983298539,
      "grad_norm": 1.4243550300598145,
      "learning_rate": 0.00020929402432575355,
      "loss": 1.6757,
      "step": 2390
    },
    {
      "epoch": 0.6263048016701461,
      "grad_norm": 1.994913101196289,
      "learning_rate": 0.00020889740877842408,
      "loss": 1.8918,
      "step": 2400
    },
    {
      "epoch": 0.6263048016701461,
      "eval_loss": 1.8121318817138672,
      "eval_runtime": 2.8513,
      "eval_samples_per_second": 42.086,
      "eval_steps_per_second": 5.261,
      "step": 2400
    },
    {
      "epoch": 0.6289144050104384,
      "grad_norm": 2.049063205718994,
      "learning_rate": 0.00020850079323109463,
      "loss": 1.7819,
      "step": 2410
    },
    {
      "epoch": 0.6315240083507306,
      "grad_norm": 1.8567708730697632,
      "learning_rate": 0.00020810417768376516,
      "loss": 1.7979,
      "step": 2420
    },
    {
      "epoch": 0.634133611691023,
      "grad_norm": 1.5748132467269897,
      "learning_rate": 0.00020770756213643574,
      "loss": 1.9863,
      "step": 2430
    },
    {
      "epoch": 0.6367432150313153,
      "grad_norm": 1.7025763988494873,
      "learning_rate": 0.00020731094658910627,
      "loss": 1.9328,
      "step": 2440
    },
    {
      "epoch": 0.6393528183716075,
      "grad_norm": 1.674764633178711,
      "learning_rate": 0.00020691433104177683,
      "loss": 1.737,
      "step": 2450
    },
    {
      "epoch": 0.6419624217118998,
      "grad_norm": 1.4378108978271484,
      "learning_rate": 0.00020651771549444736,
      "loss": 1.9106,
      "step": 2460
    },
    {
      "epoch": 0.644572025052192,
      "grad_norm": 1.7520506381988525,
      "learning_rate": 0.0002061210999471179,
      "loss": 1.9421,
      "step": 2470
    },
    {
      "epoch": 0.6471816283924844,
      "grad_norm": 1.1433526277542114,
      "learning_rate": 0.00020572448439978844,
      "loss": 2.0553,
      "step": 2480
    },
    {
      "epoch": 0.6497912317327766,
      "grad_norm": 1.3166009187698364,
      "learning_rate": 0.00020532786885245902,
      "loss": 2.0537,
      "step": 2490
    },
    {
      "epoch": 0.6524008350730689,
      "grad_norm": 1.4449753761291504,
      "learning_rate": 0.00020493125330512955,
      "loss": 1.676,
      "step": 2500
    },
    {
      "epoch": 0.6550104384133612,
      "grad_norm": 1.9771817922592163,
      "learning_rate": 0.0002045346377578001,
      "loss": 1.8364,
      "step": 2510
    },
    {
      "epoch": 0.6576200417536534,
      "grad_norm": 1.6041003465652466,
      "learning_rate": 0.00020413802221047063,
      "loss": 2.0072,
      "step": 2520
    },
    {
      "epoch": 0.6602296450939458,
      "grad_norm": 1.7406338453292847,
      "learning_rate": 0.0002037414066631412,
      "loss": 1.8019,
      "step": 2530
    },
    {
      "epoch": 0.662839248434238,
      "grad_norm": 1.2800934314727783,
      "learning_rate": 0.00020334479111581172,
      "loss": 1.9632,
      "step": 2540
    },
    {
      "epoch": 0.6654488517745303,
      "grad_norm": 1.3522264957427979,
      "learning_rate": 0.00020294817556848225,
      "loss": 1.99,
      "step": 2550
    },
    {
      "epoch": 0.6680584551148225,
      "grad_norm": 1.9305692911148071,
      "learning_rate": 0.0002025515600211528,
      "loss": 1.8235,
      "step": 2560
    },
    {
      "epoch": 0.6706680584551148,
      "grad_norm": 2.2346138954162598,
      "learning_rate": 0.00020215494447382333,
      "loss": 2.1077,
      "step": 2570
    },
    {
      "epoch": 0.673277661795407,
      "grad_norm": 1.6917130947113037,
      "learning_rate": 0.0002017583289264939,
      "loss": 1.9639,
      "step": 2580
    },
    {
      "epoch": 0.6758872651356994,
      "grad_norm": 1.1857826709747314,
      "learning_rate": 0.00020136171337916444,
      "loss": 1.5948,
      "step": 2590
    },
    {
      "epoch": 0.6784968684759917,
      "grad_norm": 1.6492305994033813,
      "learning_rate": 0.000200965097831835,
      "loss": 2.0323,
      "step": 2600
    },
    {
      "epoch": 0.6784968684759917,
      "eval_loss": 1.7971107959747314,
      "eval_runtime": 2.8492,
      "eval_samples_per_second": 42.117,
      "eval_steps_per_second": 5.265,
      "step": 2600
    },
    {
      "epoch": 0.6811064718162839,
      "grad_norm": 1.8077038526535034,
      "learning_rate": 0.00020056848228450553,
      "loss": 1.89,
      "step": 2610
    },
    {
      "epoch": 0.6837160751565762,
      "grad_norm": 1.5067633390426636,
      "learning_rate": 0.00020017186673717608,
      "loss": 1.8711,
      "step": 2620
    },
    {
      "epoch": 0.6863256784968684,
      "grad_norm": 1.675858497619629,
      "learning_rate": 0.0001997752511898466,
      "loss": 1.842,
      "step": 2630
    },
    {
      "epoch": 0.6889352818371608,
      "grad_norm": 1.8353943824768066,
      "learning_rate": 0.0001993786356425172,
      "loss": 1.8234,
      "step": 2640
    },
    {
      "epoch": 0.691544885177453,
      "grad_norm": 1.4432040452957153,
      "learning_rate": 0.00019898202009518772,
      "loss": 1.6153,
      "step": 2650
    },
    {
      "epoch": 0.6941544885177453,
      "grad_norm": 1.6104414463043213,
      "learning_rate": 0.00019858540454785828,
      "loss": 1.839,
      "step": 2660
    },
    {
      "epoch": 0.6967640918580376,
      "grad_norm": 1.2969093322753906,
      "learning_rate": 0.0001981887890005288,
      "loss": 1.6911,
      "step": 2670
    },
    {
      "epoch": 0.6993736951983298,
      "grad_norm": 1.7772544622421265,
      "learning_rate": 0.00019779217345319933,
      "loss": 1.7022,
      "step": 2680
    },
    {
      "epoch": 0.7019832985386222,
      "grad_norm": 2.0440120697021484,
      "learning_rate": 0.0001973955579058699,
      "loss": 1.8047,
      "step": 2690
    },
    {
      "epoch": 0.7045929018789144,
      "grad_norm": 1.4984396696090698,
      "learning_rate": 0.00019699894235854042,
      "loss": 1.9989,
      "step": 2700
    },
    {
      "epoch": 0.7072025052192067,
      "grad_norm": 1.3547061681747437,
      "learning_rate": 0.00019660232681121097,
      "loss": 1.6927,
      "step": 2710
    },
    {
      "epoch": 0.7098121085594989,
      "grad_norm": 2.3433659076690674,
      "learning_rate": 0.00019620571126388153,
      "loss": 1.8193,
      "step": 2720
    },
    {
      "epoch": 0.7124217118997912,
      "grad_norm": 1.2021064758300781,
      "learning_rate": 0.00019580909571655208,
      "loss": 1.7191,
      "step": 2730
    },
    {
      "epoch": 0.7150313152400835,
      "grad_norm": 1.7056968212127686,
      "learning_rate": 0.0001954124801692226,
      "loss": 1.6977,
      "step": 2740
    },
    {
      "epoch": 0.7176409185803758,
      "grad_norm": 1.592691421508789,
      "learning_rate": 0.00019501586462189317,
      "loss": 1.9077,
      "step": 2750
    },
    {
      "epoch": 0.7202505219206681,
      "grad_norm": 1.6552919149398804,
      "learning_rate": 0.0001946192490745637,
      "loss": 1.998,
      "step": 2760
    },
    {
      "epoch": 0.7228601252609603,
      "grad_norm": 1.567521095275879,
      "learning_rate": 0.00019422263352723425,
      "loss": 1.7692,
      "step": 2770
    },
    {
      "epoch": 0.7254697286012526,
      "grad_norm": 1.651289463043213,
      "learning_rate": 0.00019382601797990478,
      "loss": 2.0726,
      "step": 2780
    },
    {
      "epoch": 0.7280793319415448,
      "grad_norm": 1.8088752031326294,
      "learning_rate": 0.00019342940243257536,
      "loss": 1.88,
      "step": 2790
    },
    {
      "epoch": 0.7306889352818372,
      "grad_norm": 1.9129524230957031,
      "learning_rate": 0.0001930327868852459,
      "loss": 1.7397,
      "step": 2800
    },
    {
      "epoch": 0.7306889352818372,
      "eval_loss": 1.7830088138580322,
      "eval_runtime": 2.8469,
      "eval_samples_per_second": 42.151,
      "eval_steps_per_second": 5.269,
      "step": 2800
    },
    {
      "epoch": 0.7332985386221295,
      "grad_norm": 1.4335486888885498,
      "learning_rate": 0.00019263617133791645,
      "loss": 1.941,
      "step": 2810
    },
    {
      "epoch": 0.7359081419624217,
      "grad_norm": 1.3551886081695557,
      "learning_rate": 0.00019223955579058698,
      "loss": 1.7714,
      "step": 2820
    },
    {
      "epoch": 0.738517745302714,
      "grad_norm": 1.2772573232650757,
      "learning_rate": 0.0001918429402432575,
      "loss": 1.8933,
      "step": 2830
    },
    {
      "epoch": 0.7411273486430062,
      "grad_norm": 2.4683685302734375,
      "learning_rate": 0.00019144632469592806,
      "loss": 1.8938,
      "step": 2840
    },
    {
      "epoch": 0.7437369519832986,
      "grad_norm": 1.6084165573120117,
      "learning_rate": 0.0001910497091485986,
      "loss": 1.7982,
      "step": 2850
    },
    {
      "epoch": 0.7463465553235908,
      "grad_norm": 1.4565116167068481,
      "learning_rate": 0.00019065309360126917,
      "loss": 1.798,
      "step": 2860
    },
    {
      "epoch": 0.7489561586638831,
      "grad_norm": 1.438899040222168,
      "learning_rate": 0.0001902564780539397,
      "loss": 1.7734,
      "step": 2870
    },
    {
      "epoch": 0.7515657620041754,
      "grad_norm": 1.6877135038375854,
      "learning_rate": 0.00018985986250661025,
      "loss": 2.0493,
      "step": 2880
    },
    {
      "epoch": 0.7541753653444676,
      "grad_norm": 1.3055468797683716,
      "learning_rate": 0.00018946324695928078,
      "loss": 1.9336,
      "step": 2890
    },
    {
      "epoch": 0.7567849686847599,
      "grad_norm": 2.262821912765503,
      "learning_rate": 0.00018906663141195134,
      "loss": 1.8942,
      "step": 2900
    },
    {
      "epoch": 0.7593945720250522,
      "grad_norm": 2.1491498947143555,
      "learning_rate": 0.00018867001586462187,
      "loss": 1.7687,
      "step": 2910
    },
    {
      "epoch": 0.7620041753653445,
      "grad_norm": 1.5393651723861694,
      "learning_rate": 0.00018827340031729242,
      "loss": 1.6905,
      "step": 2920
    },
    {
      "epoch": 0.7646137787056367,
      "grad_norm": 1.5987889766693115,
      "learning_rate": 0.00018787678476996295,
      "loss": 2.0798,
      "step": 2930
    },
    {
      "epoch": 0.767223382045929,
      "grad_norm": 1.7215607166290283,
      "learning_rate": 0.00018748016922263353,
      "loss": 1.6426,
      "step": 2940
    },
    {
      "epoch": 0.7698329853862212,
      "grad_norm": 1.3743910789489746,
      "learning_rate": 0.00018708355367530406,
      "loss": 1.8361,
      "step": 2950
    },
    {
      "epoch": 0.7724425887265136,
      "grad_norm": 1.276522159576416,
      "learning_rate": 0.00018668693812797462,
      "loss": 1.6309,
      "step": 2960
    },
    {
      "epoch": 0.7750521920668059,
      "grad_norm": 1.817722201347351,
      "learning_rate": 0.00018629032258064515,
      "loss": 1.7545,
      "step": 2970
    },
    {
      "epoch": 0.7776617954070981,
      "grad_norm": 1.3181954622268677,
      "learning_rate": 0.00018589370703331567,
      "loss": 1.7205,
      "step": 2980
    },
    {
      "epoch": 0.7802713987473904,
      "grad_norm": 1.4634281396865845,
      "learning_rate": 0.00018549709148598623,
      "loss": 1.756,
      "step": 2990
    },
    {
      "epoch": 0.7828810020876826,
      "grad_norm": 1.86090087890625,
      "learning_rate": 0.00018510047593865676,
      "loss": 1.9948,
      "step": 3000
    },
    {
      "epoch": 0.7828810020876826,
      "eval_loss": 1.768606424331665,
      "eval_runtime": 2.8469,
      "eval_samples_per_second": 42.152,
      "eval_steps_per_second": 5.269,
      "step": 3000
    },
    {
      "epoch": 0.785490605427975,
      "grad_norm": 1.4341187477111816,
      "learning_rate": 0.00018470386039132734,
      "loss": 1.8477,
      "step": 3010
    },
    {
      "epoch": 0.7881002087682673,
      "grad_norm": 1.4991616010665894,
      "learning_rate": 0.00018430724484399787,
      "loss": 1.8485,
      "step": 3020
    },
    {
      "epoch": 0.7907098121085595,
      "grad_norm": 2.011587381362915,
      "learning_rate": 0.00018391062929666842,
      "loss": 1.8828,
      "step": 3030
    },
    {
      "epoch": 0.7933194154488518,
      "grad_norm": 1.6999995708465576,
      "learning_rate": 0.00018351401374933895,
      "loss": 1.9551,
      "step": 3040
    },
    {
      "epoch": 0.795929018789144,
      "grad_norm": 1.9030050039291382,
      "learning_rate": 0.0001831173982020095,
      "loss": 1.7662,
      "step": 3050
    },
    {
      "epoch": 0.7985386221294363,
      "grad_norm": 1.8964786529541016,
      "learning_rate": 0.00018272078265468004,
      "loss": 1.9568,
      "step": 3060
    },
    {
      "epoch": 0.8011482254697286,
      "grad_norm": 1.511259913444519,
      "learning_rate": 0.0001823241671073506,
      "loss": 1.6745,
      "step": 3070
    },
    {
      "epoch": 0.8037578288100209,
      "grad_norm": 2.8171370029449463,
      "learning_rate": 0.00018192755156002112,
      "loss": 1.5187,
      "step": 3080
    },
    {
      "epoch": 0.8063674321503131,
      "grad_norm": 1.9588807821273804,
      "learning_rate": 0.0001815309360126917,
      "loss": 1.8799,
      "step": 3090
    },
    {
      "epoch": 0.8089770354906054,
      "grad_norm": 1.565345287322998,
      "learning_rate": 0.00018113432046536223,
      "loss": 1.7591,
      "step": 3100
    },
    {
      "epoch": 0.8115866388308977,
      "grad_norm": 1.5397250652313232,
      "learning_rate": 0.00018073770491803276,
      "loss": 1.9533,
      "step": 3110
    },
    {
      "epoch": 0.81419624217119,
      "grad_norm": 1.6300170421600342,
      "learning_rate": 0.00018034108937070332,
      "loss": 1.8497,
      "step": 3120
    },
    {
      "epoch": 0.8168058455114823,
      "grad_norm": 1.2444201707839966,
      "learning_rate": 0.00017994447382337384,
      "loss": 1.9874,
      "step": 3130
    },
    {
      "epoch": 0.8194154488517745,
      "grad_norm": 1.741011619567871,
      "learning_rate": 0.0001795478582760444,
      "loss": 1.8667,
      "step": 3140
    },
    {
      "epoch": 0.8220250521920668,
      "grad_norm": 1.3175910711288452,
      "learning_rate": 0.00017915124272871493,
      "loss": 1.7901,
      "step": 3150
    },
    {
      "epoch": 0.824634655532359,
      "grad_norm": 2.6971142292022705,
      "learning_rate": 0.0001787546271813855,
      "loss": 1.9986,
      "step": 3160
    },
    {
      "epoch": 0.8272442588726514,
      "grad_norm": 1.4978243112564087,
      "learning_rate": 0.00017835801163405604,
      "loss": 1.9684,
      "step": 3170
    },
    {
      "epoch": 0.8298538622129437,
      "grad_norm": 1.4143048524856567,
      "learning_rate": 0.0001779613960867266,
      "loss": 1.8604,
      "step": 3180
    },
    {
      "epoch": 0.8324634655532359,
      "grad_norm": 1.6771944761276245,
      "learning_rate": 0.00017756478053939712,
      "loss": 1.9903,
      "step": 3190
    },
    {
      "epoch": 0.8350730688935282,
      "grad_norm": 1.5644375085830688,
      "learning_rate": 0.00017716816499206768,
      "loss": 1.9071,
      "step": 3200
    },
    {
      "epoch": 0.8350730688935282,
      "eval_loss": 1.7562212944030762,
      "eval_runtime": 2.8475,
      "eval_samples_per_second": 42.143,
      "eval_steps_per_second": 5.268,
      "step": 3200
    },
    {
      "epoch": 0.8376826722338204,
      "grad_norm": 1.4423637390136719,
      "learning_rate": 0.0001767715494447382,
      "loss": 1.7341,
      "step": 3210
    },
    {
      "epoch": 0.8402922755741128,
      "grad_norm": 1.599420189857483,
      "learning_rate": 0.0001763749338974088,
      "loss": 1.9163,
      "step": 3220
    },
    {
      "epoch": 0.842901878914405,
      "grad_norm": 1.3856422901153564,
      "learning_rate": 0.00017597831835007932,
      "loss": 1.7662,
      "step": 3230
    },
    {
      "epoch": 0.8455114822546973,
      "grad_norm": 2.093013048171997,
      "learning_rate": 0.00017558170280274987,
      "loss": 1.9048,
      "step": 3240
    },
    {
      "epoch": 0.8481210855949896,
      "grad_norm": 1.4496400356292725,
      "learning_rate": 0.0001751850872554204,
      "loss": 1.9212,
      "step": 3250
    },
    {
      "epoch": 0.8507306889352818,
      "grad_norm": 2.119527578353882,
      "learning_rate": 0.00017478847170809093,
      "loss": 1.7551,
      "step": 3260
    },
    {
      "epoch": 0.8533402922755741,
      "grad_norm": 1.5264098644256592,
      "learning_rate": 0.00017439185616076149,
      "loss": 1.8414,
      "step": 3270
    },
    {
      "epoch": 0.8559498956158664,
      "grad_norm": 2.143669605255127,
      "learning_rate": 0.00017399524061343201,
      "loss": 1.8089,
      "step": 3280
    },
    {
      "epoch": 0.8585594989561587,
      "grad_norm": 1.5709420442581177,
      "learning_rate": 0.00017359862506610257,
      "loss": 2.1047,
      "step": 3290
    },
    {
      "epoch": 0.8611691022964509,
      "grad_norm": 1.8106886148452759,
      "learning_rate": 0.0001732020095187731,
      "loss": 1.7781,
      "step": 3300
    },
    {
      "epoch": 0.8637787056367432,
      "grad_norm": 1.9117043018341064,
      "learning_rate": 0.00017280539397144368,
      "loss": 1.8453,
      "step": 3310
    },
    {
      "epoch": 0.8663883089770354,
      "grad_norm": 1.7095386981964111,
      "learning_rate": 0.0001724087784241142,
      "loss": 1.8251,
      "step": 3320
    },
    {
      "epoch": 0.8689979123173278,
      "grad_norm": 2.0611183643341064,
      "learning_rate": 0.00017201216287678476,
      "loss": 1.866,
      "step": 3330
    },
    {
      "epoch": 0.8716075156576201,
      "grad_norm": 1.6607345342636108,
      "learning_rate": 0.0001716155473294553,
      "loss": 1.7204,
      "step": 3340
    },
    {
      "epoch": 0.8742171189979123,
      "grad_norm": 1.5106184482574463,
      "learning_rate": 0.00017121893178212585,
      "loss": 1.7885,
      "step": 3350
    },
    {
      "epoch": 0.8768267223382046,
      "grad_norm": 1.412500023841858,
      "learning_rate": 0.00017082231623479638,
      "loss": 1.632,
      "step": 3360
    },
    {
      "epoch": 0.8794363256784968,
      "grad_norm": 1.4443085193634033,
      "learning_rate": 0.00017042570068746696,
      "loss": 1.8318,
      "step": 3370
    },
    {
      "epoch": 0.8820459290187892,
      "grad_norm": 1.5635473728179932,
      "learning_rate": 0.0001700290851401375,
      "loss": 1.7069,
      "step": 3380
    },
    {
      "epoch": 0.8846555323590815,
      "grad_norm": 1.866441249847412,
      "learning_rate": 0.00016963246959280802,
      "loss": 1.9017,
      "step": 3390
    },
    {
      "epoch": 0.8872651356993737,
      "grad_norm": 1.7490159273147583,
      "learning_rate": 0.00016923585404547857,
      "loss": 1.739,
      "step": 3400
    },
    {
      "epoch": 0.8872651356993737,
      "eval_loss": 1.7431682348251343,
      "eval_runtime": 2.8467,
      "eval_samples_per_second": 42.154,
      "eval_steps_per_second": 5.269,
      "step": 3400
    },
    {
      "epoch": 0.889874739039666,
      "grad_norm": 1.4190012216567993,
      "learning_rate": 0.0001688392384981491,
      "loss": 1.7326,
      "step": 3410
    },
    {
      "epoch": 0.8924843423799582,
      "grad_norm": 1.436418890953064,
      "learning_rate": 0.00016844262295081966,
      "loss": 1.9979,
      "step": 3420
    },
    {
      "epoch": 0.8950939457202505,
      "grad_norm": 1.7810126543045044,
      "learning_rate": 0.00016804600740349018,
      "loss": 1.9278,
      "step": 3430
    },
    {
      "epoch": 0.8977035490605428,
      "grad_norm": 1.3648371696472168,
      "learning_rate": 0.00016764939185616074,
      "loss": 1.7597,
      "step": 3440
    },
    {
      "epoch": 0.9003131524008351,
      "grad_norm": 1.3896030187606812,
      "learning_rate": 0.0001672527763088313,
      "loss": 1.8106,
      "step": 3450
    },
    {
      "epoch": 0.9029227557411273,
      "grad_norm": 1.3404325246810913,
      "learning_rate": 0.00016685616076150185,
      "loss": 1.7716,
      "step": 3460
    },
    {
      "epoch": 0.9055323590814196,
      "grad_norm": 1.2525476217269897,
      "learning_rate": 0.00016645954521417238,
      "loss": 1.8947,
      "step": 3470
    },
    {
      "epoch": 0.9081419624217119,
      "grad_norm": 1.6850149631500244,
      "learning_rate": 0.00016606292966684294,
      "loss": 1.8595,
      "step": 3480
    },
    {
      "epoch": 0.9107515657620042,
      "grad_norm": 2.1489527225494385,
      "learning_rate": 0.00016566631411951346,
      "loss": 1.9672,
      "step": 3490
    },
    {
      "epoch": 0.9133611691022965,
      "grad_norm": 1.0923004150390625,
      "learning_rate": 0.00016526969857218402,
      "loss": 1.7559,
      "step": 3500
    },
    {
      "epoch": 0.9159707724425887,
      "grad_norm": 1.6635687351226807,
      "learning_rate": 0.00016487308302485455,
      "loss": 1.8825,
      "step": 3510
    },
    {
      "epoch": 0.918580375782881,
      "grad_norm": 1.5763553380966187,
      "learning_rate": 0.00016447646747752513,
      "loss": 1.7399,
      "step": 3520
    },
    {
      "epoch": 0.9211899791231732,
      "grad_norm": 1.7094860076904297,
      "learning_rate": 0.00016407985193019566,
      "loss": 1.9035,
      "step": 3530
    },
    {
      "epoch": 0.9237995824634656,
      "grad_norm": 2.1147055625915527,
      "learning_rate": 0.0001636832363828662,
      "loss": 1.7977,
      "step": 3540
    },
    {
      "epoch": 0.9264091858037579,
      "grad_norm": 1.5195684432983398,
      "learning_rate": 0.00016328662083553674,
      "loss": 1.7584,
      "step": 3550
    },
    {
      "epoch": 0.9290187891440501,
      "grad_norm": 1.553766131401062,
      "learning_rate": 0.00016289000528820727,
      "loss": 1.7888,
      "step": 3560
    },
    {
      "epoch": 0.9316283924843424,
      "grad_norm": 1.4916423559188843,
      "learning_rate": 0.00016249338974087783,
      "loss": 1.8132,
      "step": 3570
    },
    {
      "epoch": 0.9342379958246346,
      "grad_norm": 1.3085118532180786,
      "learning_rate": 0.00016209677419354835,
      "loss": 1.7516,
      "step": 3580
    },
    {
      "epoch": 0.9368475991649269,
      "grad_norm": 1.4562076330184937,
      "learning_rate": 0.00016170015864621894,
      "loss": 1.9721,
      "step": 3590
    },
    {
      "epoch": 0.9394572025052192,
      "grad_norm": 1.8138017654418945,
      "learning_rate": 0.00016130354309888947,
      "loss": 1.781,
      "step": 3600
    },
    {
      "epoch": 0.9394572025052192,
      "eval_loss": 1.733004093170166,
      "eval_runtime": 2.8457,
      "eval_samples_per_second": 42.168,
      "eval_steps_per_second": 5.271,
      "step": 3600
    },
    {
      "epoch": 0.9420668058455115,
      "grad_norm": 1.212538242340088,
      "learning_rate": 0.00016090692755156002,
      "loss": 1.8848,
      "step": 3610
    },
    {
      "epoch": 0.9446764091858038,
      "grad_norm": 1.4631940126419067,
      "learning_rate": 0.00016051031200423055,
      "loss": 1.7002,
      "step": 3620
    },
    {
      "epoch": 0.947286012526096,
      "grad_norm": 1.8319206237792969,
      "learning_rate": 0.0001601136964569011,
      "loss": 1.4369,
      "step": 3630
    },
    {
      "epoch": 0.9498956158663883,
      "grad_norm": 2.497696876525879,
      "learning_rate": 0.00015971708090957163,
      "loss": 2.0366,
      "step": 3640
    },
    {
      "epoch": 0.9525052192066806,
      "grad_norm": 2.056358814239502,
      "learning_rate": 0.0001593204653622422,
      "loss": 1.8002,
      "step": 3650
    },
    {
      "epoch": 0.9551148225469729,
      "grad_norm": 1.5357311964035034,
      "learning_rate": 0.00015892384981491272,
      "loss": 1.9745,
      "step": 3660
    },
    {
      "epoch": 0.9577244258872651,
      "grad_norm": 2.4383819103240967,
      "learning_rate": 0.0001585272342675833,
      "loss": 1.7879,
      "step": 3670
    },
    {
      "epoch": 0.9603340292275574,
      "grad_norm": 1.5102874040603638,
      "learning_rate": 0.00015813061872025383,
      "loss": 2.001,
      "step": 3680
    },
    {
      "epoch": 0.9629436325678496,
      "grad_norm": 1.6846468448638916,
      "learning_rate": 0.00015773400317292436,
      "loss": 1.5108,
      "step": 3690
    },
    {
      "epoch": 0.965553235908142,
      "grad_norm": 1.814603328704834,
      "learning_rate": 0.0001573373876255949,
      "loss": 1.5874,
      "step": 3700
    },
    {
      "epoch": 0.9681628392484343,
      "grad_norm": 1.7579455375671387,
      "learning_rate": 0.00015694077207826544,
      "loss": 1.6723,
      "step": 3710
    },
    {
      "epoch": 0.9707724425887265,
      "grad_norm": 1.3491244316101074,
      "learning_rate": 0.000156544156530936,
      "loss": 1.9907,
      "step": 3720
    },
    {
      "epoch": 0.9733820459290188,
      "grad_norm": 1.241881251335144,
      "learning_rate": 0.00015614754098360653,
      "loss": 1.8,
      "step": 3730
    },
    {
      "epoch": 0.975991649269311,
      "grad_norm": 2.1574580669403076,
      "learning_rate": 0.0001557509254362771,
      "loss": 1.8901,
      "step": 3740
    },
    {
      "epoch": 0.9786012526096033,
      "grad_norm": 1.7371999025344849,
      "learning_rate": 0.00015535430988894764,
      "loss": 1.8592,
      "step": 3750
    },
    {
      "epoch": 0.9812108559498957,
      "grad_norm": 1.1860970258712769,
      "learning_rate": 0.0001549576943416182,
      "loss": 1.8615,
      "step": 3760
    },
    {
      "epoch": 0.9838204592901879,
      "grad_norm": 1.7203238010406494,
      "learning_rate": 0.00015456107879428872,
      "loss": 1.9156,
      "step": 3770
    },
    {
      "epoch": 0.9864300626304802,
      "grad_norm": 1.6861761808395386,
      "learning_rate": 0.00015416446324695928,
      "loss": 1.9078,
      "step": 3780
    },
    {
      "epoch": 0.9890396659707724,
      "grad_norm": 1.2820758819580078,
      "learning_rate": 0.0001537678476996298,
      "loss": 1.6386,
      "step": 3790
    },
    {
      "epoch": 0.9916492693110647,
      "grad_norm": 2.005070447921753,
      "learning_rate": 0.00015337123215230036,
      "loss": 1.8211,
      "step": 3800
    },
    {
      "epoch": 0.9916492693110647,
      "eval_loss": 1.7220014333724976,
      "eval_runtime": 2.849,
      "eval_samples_per_second": 42.119,
      "eval_steps_per_second": 5.265,
      "step": 3800
    },
    {
      "epoch": 0.994258872651357,
      "grad_norm": 1.2658686637878418,
      "learning_rate": 0.0001529746166049709,
      "loss": 1.8031,
      "step": 3810
    },
    {
      "epoch": 0.9968684759916493,
      "grad_norm": 1.4198609590530396,
      "learning_rate": 0.00015257800105764144,
      "loss": 1.7273,
      "step": 3820
    },
    {
      "epoch": 0.9994780793319415,
      "grad_norm": 1.3511502742767334,
      "learning_rate": 0.000152181385510312,
      "loss": 1.6796,
      "step": 3830
    },
    {
      "epoch": 1.0020876826722338,
      "grad_norm": 1.6582612991333008,
      "learning_rate": 0.00015178476996298253,
      "loss": 1.6563,
      "step": 3840
    },
    {
      "epoch": 1.004697286012526,
      "grad_norm": 1.7953635454177856,
      "learning_rate": 0.00015138815441565308,
      "loss": 1.6766,
      "step": 3850
    },
    {
      "epoch": 1.0073068893528183,
      "grad_norm": 1.6864932775497437,
      "learning_rate": 0.0001509915388683236,
      "loss": 1.7337,
      "step": 3860
    },
    {
      "epoch": 1.0099164926931106,
      "grad_norm": 1.738526701927185,
      "learning_rate": 0.00015059492332099417,
      "loss": 1.5833,
      "step": 3870
    },
    {
      "epoch": 1.0125260960334028,
      "grad_norm": 1.5012314319610596,
      "learning_rate": 0.0001501983077736647,
      "loss": 1.678,
      "step": 3880
    },
    {
      "epoch": 1.0151356993736953,
      "grad_norm": 1.3589788675308228,
      "learning_rate": 0.00014980169222633525,
      "loss": 1.6418,
      "step": 3890
    },
    {
      "epoch": 1.0177453027139876,
      "grad_norm": 2.211846351623535,
      "learning_rate": 0.0001494050766790058,
      "loss": 1.6539,
      "step": 3900
    },
    {
      "epoch": 1.0203549060542798,
      "grad_norm": 1.5531141757965088,
      "learning_rate": 0.00014900846113167634,
      "loss": 1.9735,
      "step": 3910
    },
    {
      "epoch": 1.022964509394572,
      "grad_norm": 1.8782341480255127,
      "learning_rate": 0.0001486118455843469,
      "loss": 1.7231,
      "step": 3920
    },
    {
      "epoch": 1.0255741127348643,
      "grad_norm": 1.795080542564392,
      "learning_rate": 0.00014821523003701745,
      "loss": 1.7603,
      "step": 3930
    },
    {
      "epoch": 1.0281837160751566,
      "grad_norm": 1.4155910015106201,
      "learning_rate": 0.00014781861448968797,
      "loss": 1.7345,
      "step": 3940
    },
    {
      "epoch": 1.0307933194154488,
      "grad_norm": 1.5518951416015625,
      "learning_rate": 0.00014742199894235853,
      "loss": 1.7433,
      "step": 3950
    },
    {
      "epoch": 1.033402922755741,
      "grad_norm": 1.4352359771728516,
      "learning_rate": 0.00014702538339502909,
      "loss": 1.8413,
      "step": 3960
    },
    {
      "epoch": 1.0360125260960333,
      "grad_norm": 1.7695972919464111,
      "learning_rate": 0.00014662876784769961,
      "loss": 1.7342,
      "step": 3970
    },
    {
      "epoch": 1.0386221294363256,
      "grad_norm": 1.7211581468582153,
      "learning_rate": 0.00014623215230037017,
      "loss": 1.9872,
      "step": 3980
    },
    {
      "epoch": 1.0412317327766178,
      "grad_norm": 1.7671327590942383,
      "learning_rate": 0.0001458355367530407,
      "loss": 1.6672,
      "step": 3990
    },
    {
      "epoch": 1.0438413361169103,
      "grad_norm": 1.848870873451233,
      "learning_rate": 0.00014543892120571125,
      "loss": 1.7177,
      "step": 4000
    },
    {
      "epoch": 1.0438413361169103,
      "eval_loss": 1.716819167137146,
      "eval_runtime": 2.8488,
      "eval_samples_per_second": 42.124,
      "eval_steps_per_second": 5.265,
      "step": 4000
    },
    {
      "epoch": 1.0464509394572026,
      "grad_norm": 1.763754963874817,
      "learning_rate": 0.0001450423056583818,
      "loss": 1.7389,
      "step": 4010
    },
    {
      "epoch": 1.0490605427974948,
      "grad_norm": 1.3335784673690796,
      "learning_rate": 0.00014464569011105234,
      "loss": 1.9317,
      "step": 4020
    },
    {
      "epoch": 1.051670146137787,
      "grad_norm": 1.8693541288375854,
      "learning_rate": 0.00014424907456372287,
      "loss": 1.5441,
      "step": 4030
    },
    {
      "epoch": 1.0542797494780793,
      "grad_norm": 1.7710320949554443,
      "learning_rate": 0.00014385245901639342,
      "loss": 2.0764,
      "step": 4040
    },
    {
      "epoch": 1.0568893528183716,
      "grad_norm": 2.001025676727295,
      "learning_rate": 0.00014345584346906398,
      "loss": 1.4656,
      "step": 4050
    },
    {
      "epoch": 1.0594989561586639,
      "grad_norm": 2.1108505725860596,
      "learning_rate": 0.0001430592279217345,
      "loss": 1.7411,
      "step": 4060
    },
    {
      "epoch": 1.062108559498956,
      "grad_norm": 2.1583664417266846,
      "learning_rate": 0.00014266261237440506,
      "loss": 1.7115,
      "step": 4070
    },
    {
      "epoch": 1.0647181628392484,
      "grad_norm": 2.0016162395477295,
      "learning_rate": 0.00014226599682707562,
      "loss": 1.509,
      "step": 4080
    },
    {
      "epoch": 1.0673277661795406,
      "grad_norm": 1.424812912940979,
      "learning_rate": 0.00014186938127974614,
      "loss": 1.6901,
      "step": 4090
    },
    {
      "epoch": 1.0699373695198329,
      "grad_norm": 2.379870653152466,
      "learning_rate": 0.0001414727657324167,
      "loss": 1.9248,
      "step": 4100
    },
    {
      "epoch": 1.0725469728601253,
      "grad_norm": 1.8281137943267822,
      "learning_rate": 0.00014107615018508726,
      "loss": 1.7957,
      "step": 4110
    },
    {
      "epoch": 1.0751565762004176,
      "grad_norm": 2.4282984733581543,
      "learning_rate": 0.00014067953463775778,
      "loss": 1.404,
      "step": 4120
    },
    {
      "epoch": 1.0777661795407099,
      "grad_norm": 1.592094898223877,
      "learning_rate": 0.00014028291909042834,
      "loss": 1.6945,
      "step": 4130
    },
    {
      "epoch": 1.0803757828810021,
      "grad_norm": 1.6637765169143677,
      "learning_rate": 0.0001398863035430989,
      "loss": 1.5528,
      "step": 4140
    },
    {
      "epoch": 1.0829853862212944,
      "grad_norm": 2.4770336151123047,
      "learning_rate": 0.00013948968799576942,
      "loss": 1.6875,
      "step": 4150
    },
    {
      "epoch": 1.0855949895615866,
      "grad_norm": 1.5406090021133423,
      "learning_rate": 0.00013909307244843998,
      "loss": 1.71,
      "step": 4160
    },
    {
      "epoch": 1.0882045929018789,
      "grad_norm": 1.7194643020629883,
      "learning_rate": 0.0001386964569011105,
      "loss": 1.7008,
      "step": 4170
    },
    {
      "epoch": 1.0908141962421711,
      "grad_norm": 1.2618190050125122,
      "learning_rate": 0.00013829984135378104,
      "loss": 1.687,
      "step": 4180
    },
    {
      "epoch": 1.0934237995824634,
      "grad_norm": 1.5729645490646362,
      "learning_rate": 0.0001379032258064516,
      "loss": 1.5471,
      "step": 4190
    },
    {
      "epoch": 1.0960334029227556,
      "grad_norm": 1.8358595371246338,
      "learning_rate": 0.00013750661025912215,
      "loss": 1.6855,
      "step": 4200
    },
    {
      "epoch": 1.0960334029227556,
      "eval_loss": 1.7004623413085938,
      "eval_runtime": 2.8479,
      "eval_samples_per_second": 42.136,
      "eval_steps_per_second": 5.267,
      "step": 4200
    },
    {
      "epoch": 1.0986430062630481,
      "grad_norm": 1.9365723133087158,
      "learning_rate": 0.00013710999471179268,
      "loss": 1.8597,
      "step": 4210
    },
    {
      "epoch": 1.1012526096033404,
      "grad_norm": 1.7950191497802734,
      "learning_rate": 0.00013671337916446323,
      "loss": 1.7286,
      "step": 4220
    },
    {
      "epoch": 1.1038622129436326,
      "grad_norm": 1.5135202407836914,
      "learning_rate": 0.0001363167636171338,
      "loss": 1.6452,
      "step": 4230
    },
    {
      "epoch": 1.1064718162839249,
      "grad_norm": 1.2409863471984863,
      "learning_rate": 0.00013592014806980432,
      "loss": 1.5493,
      "step": 4240
    },
    {
      "epoch": 1.1090814196242171,
      "grad_norm": 1.826883316040039,
      "learning_rate": 0.00013552353252247487,
      "loss": 1.6566,
      "step": 4250
    },
    {
      "epoch": 1.1116910229645094,
      "grad_norm": 1.7278778553009033,
      "learning_rate": 0.00013512691697514543,
      "loss": 1.8085,
      "step": 4260
    },
    {
      "epoch": 1.1143006263048016,
      "grad_norm": 1.3498060703277588,
      "learning_rate": 0.00013473030142781595,
      "loss": 1.9807,
      "step": 4270
    },
    {
      "epoch": 1.116910229645094,
      "grad_norm": 1.4130845069885254,
      "learning_rate": 0.0001343336858804865,
      "loss": 1.6398,
      "step": 4280
    },
    {
      "epoch": 1.1195198329853862,
      "grad_norm": 1.3752217292785645,
      "learning_rate": 0.00013393707033315707,
      "loss": 1.6415,
      "step": 4290
    },
    {
      "epoch": 1.1221294363256784,
      "grad_norm": 1.765114188194275,
      "learning_rate": 0.0001335404547858276,
      "loss": 1.715,
      "step": 4300
    },
    {
      "epoch": 1.1247390396659709,
      "grad_norm": 1.7525005340576172,
      "learning_rate": 0.00013314383923849815,
      "loss": 1.5717,
      "step": 4310
    },
    {
      "epoch": 1.1273486430062631,
      "grad_norm": 1.851449966430664,
      "learning_rate": 0.00013274722369116868,
      "loss": 1.8408,
      "step": 4320
    },
    {
      "epoch": 1.1299582463465554,
      "grad_norm": 2.1715667247772217,
      "learning_rate": 0.00013235060814383923,
      "loss": 1.7948,
      "step": 4330
    },
    {
      "epoch": 1.1325678496868476,
      "grad_norm": 1.735262155532837,
      "learning_rate": 0.00013195399259650976,
      "loss": 1.843,
      "step": 4340
    },
    {
      "epoch": 1.13517745302714,
      "grad_norm": 1.5172371864318848,
      "learning_rate": 0.00013155737704918032,
      "loss": 1.6107,
      "step": 4350
    },
    {
      "epoch": 1.1377870563674322,
      "grad_norm": 1.30751633644104,
      "learning_rate": 0.00013116076150185085,
      "loss": 1.7114,
      "step": 4360
    },
    {
      "epoch": 1.1403966597077244,
      "grad_norm": 1.4059326648712158,
      "learning_rate": 0.0001307641459545214,
      "loss": 1.6643,
      "step": 4370
    },
    {
      "epoch": 1.1430062630480167,
      "grad_norm": 1.552335500717163,
      "learning_rate": 0.00013036753040719196,
      "loss": 1.5434,
      "step": 4380
    },
    {
      "epoch": 1.145615866388309,
      "grad_norm": 2.119539976119995,
      "learning_rate": 0.00012997091485986249,
      "loss": 1.4821,
      "step": 4390
    },
    {
      "epoch": 1.1482254697286012,
      "grad_norm": 1.796188473701477,
      "learning_rate": 0.00012957429931253304,
      "loss": 1.5876,
      "step": 4400
    },
    {
      "epoch": 1.1482254697286012,
      "eval_loss": 1.6989279985427856,
      "eval_runtime": 2.8474,
      "eval_samples_per_second": 42.144,
      "eval_steps_per_second": 5.268,
      "step": 4400
    },
    {
      "epoch": 1.1508350730688934,
      "grad_norm": 1.6481208801269531,
      "learning_rate": 0.0001291776837652036,
      "loss": 1.5819,
      "step": 4410
    },
    {
      "epoch": 1.153444676409186,
      "grad_norm": 2.205301523208618,
      "learning_rate": 0.00012878106821787412,
      "loss": 1.6284,
      "step": 4420
    },
    {
      "epoch": 1.1560542797494782,
      "grad_norm": 1.3275721073150635,
      "learning_rate": 0.00012838445267054468,
      "loss": 1.6477,
      "step": 4430
    },
    {
      "epoch": 1.1586638830897704,
      "grad_norm": 1.5473114252090454,
      "learning_rate": 0.00012798783712321524,
      "loss": 1.6744,
      "step": 4440
    },
    {
      "epoch": 1.1612734864300627,
      "grad_norm": 1.398019790649414,
      "learning_rate": 0.00012759122157588576,
      "loss": 1.7257,
      "step": 4450
    },
    {
      "epoch": 1.163883089770355,
      "grad_norm": 1.3983607292175293,
      "learning_rate": 0.0001271946060285563,
      "loss": 1.8447,
      "step": 4460
    },
    {
      "epoch": 1.1664926931106472,
      "grad_norm": 1.5334426164627075,
      "learning_rate": 0.00012679799048122685,
      "loss": 1.6166,
      "step": 4470
    },
    {
      "epoch": 1.1691022964509394,
      "grad_norm": 1.708626627922058,
      "learning_rate": 0.0001264013749338974,
      "loss": 1.6512,
      "step": 4480
    },
    {
      "epoch": 1.1717118997912317,
      "grad_norm": 1.2040351629257202,
      "learning_rate": 0.00012600475938656793,
      "loss": 1.6492,
      "step": 4490
    },
    {
      "epoch": 1.174321503131524,
      "grad_norm": 1.9607155323028564,
      "learning_rate": 0.0001256081438392385,
      "loss": 1.7522,
      "step": 4500
    },
    {
      "epoch": 1.1769311064718162,
      "grad_norm": 1.8981214761734009,
      "learning_rate": 0.00012521152829190904,
      "loss": 1.6377,
      "step": 4510
    },
    {
      "epoch": 1.1795407098121085,
      "grad_norm": 2.1684255599975586,
      "learning_rate": 0.00012481491274457957,
      "loss": 1.6589,
      "step": 4520
    },
    {
      "epoch": 1.182150313152401,
      "grad_norm": 1.6153348684310913,
      "learning_rate": 0.00012441829719725013,
      "loss": 1.6362,
      "step": 4530
    },
    {
      "epoch": 1.1847599164926932,
      "grad_norm": 1.9380419254302979,
      "learning_rate": 0.00012402168164992066,
      "loss": 1.458,
      "step": 4540
    },
    {
      "epoch": 1.1873695198329854,
      "grad_norm": 1.8434971570968628,
      "learning_rate": 0.0001236250661025912,
      "loss": 1.881,
      "step": 4550
    },
    {
      "epoch": 1.1899791231732777,
      "grad_norm": 1.0723884105682373,
      "learning_rate": 0.00012322845055526177,
      "loss": 1.6562,
      "step": 4560
    },
    {
      "epoch": 1.19258872651357,
      "grad_norm": 1.2689162492752075,
      "learning_rate": 0.0001228318350079323,
      "loss": 1.8245,
      "step": 4570
    },
    {
      "epoch": 1.1951983298538622,
      "grad_norm": 1.495427131652832,
      "learning_rate": 0.00012243521946060285,
      "loss": 1.6639,
      "step": 4580
    },
    {
      "epoch": 1.1978079331941545,
      "grad_norm": 2.017076015472412,
      "learning_rate": 0.00012203860391327339,
      "loss": 1.7708,
      "step": 4590
    },
    {
      "epoch": 1.2004175365344467,
      "grad_norm": 1.553504467010498,
      "learning_rate": 0.00012164198836594392,
      "loss": 1.5692,
      "step": 4600
    },
    {
      "epoch": 1.2004175365344467,
      "eval_loss": 1.6848434209823608,
      "eval_runtime": 2.8523,
      "eval_samples_per_second": 42.072,
      "eval_steps_per_second": 5.259,
      "step": 4600
    },
    {
      "epoch": 1.203027139874739,
      "grad_norm": 1.637550950050354,
      "learning_rate": 0.00012124537281861448,
      "loss": 1.6675,
      "step": 4610
    },
    {
      "epoch": 1.2056367432150312,
      "grad_norm": 1.5626882314682007,
      "learning_rate": 0.00012084875727128502,
      "loss": 1.7526,
      "step": 4620
    },
    {
      "epoch": 1.2082463465553235,
      "grad_norm": 2.030809164047241,
      "learning_rate": 0.00012045214172395556,
      "loss": 1.83,
      "step": 4630
    },
    {
      "epoch": 1.210855949895616,
      "grad_norm": 1.700927495956421,
      "learning_rate": 0.00012005552617662612,
      "loss": 1.5655,
      "step": 4640
    },
    {
      "epoch": 1.2134655532359082,
      "grad_norm": 1.988892912864685,
      "learning_rate": 0.00011965891062929666,
      "loss": 1.5814,
      "step": 4650
    },
    {
      "epoch": 1.2160751565762005,
      "grad_norm": 1.5523420572280884,
      "learning_rate": 0.0001192622950819672,
      "loss": 1.6727,
      "step": 4660
    },
    {
      "epoch": 1.2186847599164927,
      "grad_norm": 1.7206628322601318,
      "learning_rate": 0.00011886567953463774,
      "loss": 1.655,
      "step": 4670
    },
    {
      "epoch": 1.221294363256785,
      "grad_norm": 1.9096829891204834,
      "learning_rate": 0.0001184690639873083,
      "loss": 1.6532,
      "step": 4680
    },
    {
      "epoch": 1.2239039665970772,
      "grad_norm": 1.5158212184906006,
      "learning_rate": 0.00011807244843997884,
      "loss": 1.8282,
      "step": 4690
    },
    {
      "epoch": 1.2265135699373695,
      "grad_norm": 1.3100227117538452,
      "learning_rate": 0.00011767583289264938,
      "loss": 1.8022,
      "step": 4700
    },
    {
      "epoch": 1.2291231732776617,
      "grad_norm": 1.3305332660675049,
      "learning_rate": 0.00011727921734531994,
      "loss": 1.6845,
      "step": 4710
    },
    {
      "epoch": 1.231732776617954,
      "grad_norm": 1.666713833808899,
      "learning_rate": 0.00011688260179799048,
      "loss": 1.7099,
      "step": 4720
    },
    {
      "epoch": 1.2343423799582462,
      "grad_norm": 1.6541093587875366,
      "learning_rate": 0.00011648598625066102,
      "loss": 1.6076,
      "step": 4730
    },
    {
      "epoch": 1.2369519832985385,
      "grad_norm": 2.0712625980377197,
      "learning_rate": 0.00011608937070333155,
      "loss": 1.6103,
      "step": 4740
    },
    {
      "epoch": 1.239561586638831,
      "grad_norm": 1.7100313901901245,
      "learning_rate": 0.0001156927551560021,
      "loss": 1.6181,
      "step": 4750
    },
    {
      "epoch": 1.2421711899791232,
      "grad_norm": 1.5104538202285767,
      "learning_rate": 0.00011529613960867265,
      "loss": 1.8637,
      "step": 4760
    },
    {
      "epoch": 1.2447807933194155,
      "grad_norm": 2.479936122894287,
      "learning_rate": 0.00011489952406134319,
      "loss": 1.799,
      "step": 4770
    },
    {
      "epoch": 1.2473903966597077,
      "grad_norm": 1.5993595123291016,
      "learning_rate": 0.00011450290851401373,
      "loss": 1.8501,
      "step": 4780
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.2350456714630127,
      "learning_rate": 0.00011410629296668429,
      "loss": 1.5492,
      "step": 4790
    },
    {
      "epoch": 1.2526096033402923,
      "grad_norm": 1.9606951475143433,
      "learning_rate": 0.00011370967741935483,
      "loss": 1.8654,
      "step": 4800
    },
    {
      "epoch": 1.2526096033402923,
      "eval_loss": 1.6828811168670654,
      "eval_runtime": 2.8487,
      "eval_samples_per_second": 42.125,
      "eval_steps_per_second": 5.266,
      "step": 4800
    },
    {
      "epoch": 1.2552192066805845,
      "grad_norm": 1.3927578926086426,
      "learning_rate": 0.00011331306187202537,
      "loss": 1.7668,
      "step": 4810
    },
    {
      "epoch": 1.2578288100208768,
      "grad_norm": 1.6780742406845093,
      "learning_rate": 0.00011291644632469593,
      "loss": 1.6584,
      "step": 4820
    },
    {
      "epoch": 1.260438413361169,
      "grad_norm": 2.4790191650390625,
      "learning_rate": 0.00011251983077736647,
      "loss": 1.6583,
      "step": 4830
    },
    {
      "epoch": 1.2630480167014615,
      "grad_norm": 1.6265103816986084,
      "learning_rate": 0.00011212321523003701,
      "loss": 1.3745,
      "step": 4840
    },
    {
      "epoch": 1.2656576200417535,
      "grad_norm": 1.299709677696228,
      "learning_rate": 0.00011172659968270755,
      "loss": 1.6506,
      "step": 4850
    },
    {
      "epoch": 1.268267223382046,
      "grad_norm": 1.6793160438537598,
      "learning_rate": 0.00011132998413537811,
      "loss": 1.5809,
      "step": 4860
    },
    {
      "epoch": 1.2708768267223383,
      "grad_norm": 1.8579658269882202,
      "learning_rate": 0.00011093336858804865,
      "loss": 1.4836,
      "step": 4870
    },
    {
      "epoch": 1.2734864300626305,
      "grad_norm": 1.9511431455612183,
      "learning_rate": 0.00011053675304071919,
      "loss": 1.5185,
      "step": 4880
    },
    {
      "epoch": 1.2760960334029228,
      "grad_norm": 1.9505506753921509,
      "learning_rate": 0.00011014013749338972,
      "loss": 1.6258,
      "step": 4890
    },
    {
      "epoch": 1.278705636743215,
      "grad_norm": 1.3138914108276367,
      "learning_rate": 0.00010974352194606028,
      "loss": 1.8594,
      "step": 4900
    },
    {
      "epoch": 1.2813152400835073,
      "grad_norm": 1.3383759260177612,
      "learning_rate": 0.00010934690639873082,
      "loss": 1.7277,
      "step": 4910
    },
    {
      "epoch": 1.2839248434237995,
      "grad_norm": 1.911863923072815,
      "learning_rate": 0.00010895029085140136,
      "loss": 1.5291,
      "step": 4920
    },
    {
      "epoch": 1.2865344467640918,
      "grad_norm": 1.7002769708633423,
      "learning_rate": 0.0001085536753040719,
      "loss": 1.8003,
      "step": 4930
    },
    {
      "epoch": 1.289144050104384,
      "grad_norm": 1.7945889234542847,
      "learning_rate": 0.00010815705975674246,
      "loss": 1.7845,
      "step": 4940
    },
    {
      "epoch": 1.2917536534446765,
      "grad_norm": 1.3126462697982788,
      "learning_rate": 0.000107760444209413,
      "loss": 1.7536,
      "step": 4950
    },
    {
      "epoch": 1.2943632567849686,
      "grad_norm": 1.2250120639801025,
      "learning_rate": 0.00010736382866208354,
      "loss": 1.7758,
      "step": 4960
    },
    {
      "epoch": 1.296972860125261,
      "grad_norm": 1.6513698101043701,
      "learning_rate": 0.0001069672131147541,
      "loss": 1.8608,
      "step": 4970
    },
    {
      "epoch": 1.2995824634655533,
      "grad_norm": 1.5863265991210938,
      "learning_rate": 0.00010657059756742464,
      "loss": 2.0924,
      "step": 4980
    },
    {
      "epoch": 1.3021920668058455,
      "grad_norm": 1.7463608980178833,
      "learning_rate": 0.00010617398202009518,
      "loss": 1.6297,
      "step": 4990
    },
    {
      "epoch": 1.3048016701461378,
      "grad_norm": 2.242399215698242,
      "learning_rate": 0.00010577736647276574,
      "loss": 1.8288,
      "step": 5000
    },
    {
      "epoch": 1.3048016701461378,
      "eval_loss": 1.6817224025726318,
      "eval_runtime": 2.8476,
      "eval_samples_per_second": 42.141,
      "eval_steps_per_second": 5.268,
      "step": 5000
    },
    {
      "epoch": 1.30741127348643,
      "grad_norm": 2.4357094764709473,
      "learning_rate": 0.00010538075092543628,
      "loss": 1.6079,
      "step": 5010
    },
    {
      "epoch": 1.3100208768267223,
      "grad_norm": 2.290905237197876,
      "learning_rate": 0.00010498413537810682,
      "loss": 1.5921,
      "step": 5020
    },
    {
      "epoch": 1.3126304801670146,
      "grad_norm": 1.885697841644287,
      "learning_rate": 0.00010458751983077735,
      "loss": 1.5952,
      "step": 5030
    },
    {
      "epoch": 1.3152400835073068,
      "grad_norm": 1.6059281826019287,
      "learning_rate": 0.00010419090428344789,
      "loss": 1.7976,
      "step": 5040
    },
    {
      "epoch": 1.317849686847599,
      "grad_norm": 1.9562530517578125,
      "learning_rate": 0.00010379428873611845,
      "loss": 1.7284,
      "step": 5050
    },
    {
      "epoch": 1.3204592901878915,
      "grad_norm": 1.9027830362319946,
      "learning_rate": 0.00010339767318878899,
      "loss": 1.6983,
      "step": 5060
    },
    {
      "epoch": 1.3230688935281838,
      "grad_norm": 1.7093379497528076,
      "learning_rate": 0.00010300105764145953,
      "loss": 1.7899,
      "step": 5070
    },
    {
      "epoch": 1.325678496868476,
      "grad_norm": 1.4821460247039795,
      "learning_rate": 0.00010260444209413008,
      "loss": 1.5498,
      "step": 5080
    },
    {
      "epoch": 1.3282881002087683,
      "grad_norm": 1.3270241022109985,
      "learning_rate": 0.00010220782654680063,
      "loss": 1.7194,
      "step": 5090
    },
    {
      "epoch": 1.3308977035490606,
      "grad_norm": 1.8423353433609009,
      "learning_rate": 0.00010181121099947117,
      "loss": 1.7934,
      "step": 5100
    },
    {
      "epoch": 1.3335073068893528,
      "grad_norm": 1.511506199836731,
      "learning_rate": 0.00010141459545214171,
      "loss": 1.685,
      "step": 5110
    },
    {
      "epoch": 1.336116910229645,
      "grad_norm": 1.6198877096176147,
      "learning_rate": 0.00010101797990481227,
      "loss": 1.507,
      "step": 5120
    },
    {
      "epoch": 1.3387265135699373,
      "grad_norm": 2.1281678676605225,
      "learning_rate": 0.00010062136435748281,
      "loss": 1.6034,
      "step": 5130
    },
    {
      "epoch": 1.3413361169102296,
      "grad_norm": 2.0043513774871826,
      "learning_rate": 0.00010022474881015335,
      "loss": 1.8696,
      "step": 5140
    },
    {
      "epoch": 1.343945720250522,
      "grad_norm": 1.7305878400802612,
      "learning_rate": 9.98281332628239e-05,
      "loss": 1.8941,
      "step": 5150
    },
    {
      "epoch": 1.346555323590814,
      "grad_norm": 1.484869122505188,
      "learning_rate": 9.943151771549445e-05,
      "loss": 1.7241,
      "step": 5160
    },
    {
      "epoch": 1.3491649269311066,
      "grad_norm": 1.98412024974823,
      "learning_rate": 9.903490216816498e-05,
      "loss": 1.6358,
      "step": 5170
    },
    {
      "epoch": 1.3517745302713988,
      "grad_norm": 1.9149158000946045,
      "learning_rate": 9.863828662083552e-05,
      "loss": 1.5692,
      "step": 5180
    },
    {
      "epoch": 1.354384133611691,
      "grad_norm": 1.904144525527954,
      "learning_rate": 9.824167107350607e-05,
      "loss": 1.716,
      "step": 5190
    },
    {
      "epoch": 1.3569937369519833,
      "grad_norm": 1.5593112707138062,
      "learning_rate": 9.784505552617662e-05,
      "loss": 1.9534,
      "step": 5200
    },
    {
      "epoch": 1.3569937369519833,
      "eval_loss": 1.668105959892273,
      "eval_runtime": 2.8488,
      "eval_samples_per_second": 42.123,
      "eval_steps_per_second": 5.265,
      "step": 5200
    },
    {
      "epoch": 1.3596033402922756,
      "grad_norm": 1.238394856452942,
      "learning_rate": 9.744843997884716e-05,
      "loss": 1.758,
      "step": 5210
    },
    {
      "epoch": 1.3622129436325678,
      "grad_norm": 1.7884317636489868,
      "learning_rate": 9.70518244315177e-05,
      "loss": 1.7691,
      "step": 5220
    },
    {
      "epoch": 1.36482254697286,
      "grad_norm": 2.0335612297058105,
      "learning_rate": 9.665520888418826e-05,
      "loss": 1.6979,
      "step": 5230
    },
    {
      "epoch": 1.3674321503131524,
      "grad_norm": 1.6783720254898071,
      "learning_rate": 9.62585933368588e-05,
      "loss": 1.7771,
      "step": 5240
    },
    {
      "epoch": 1.3700417536534446,
      "grad_norm": 1.7189080715179443,
      "learning_rate": 9.586197778952934e-05,
      "loss": 1.5748,
      "step": 5250
    },
    {
      "epoch": 1.372651356993737,
      "grad_norm": 1.928147315979004,
      "learning_rate": 9.54653622421999e-05,
      "loss": 1.672,
      "step": 5260
    },
    {
      "epoch": 1.3752609603340291,
      "grad_norm": 2.20359468460083,
      "learning_rate": 9.506874669487044e-05,
      "loss": 1.7643,
      "step": 5270
    },
    {
      "epoch": 1.3778705636743216,
      "grad_norm": 1.7031275033950806,
      "learning_rate": 9.467213114754098e-05,
      "loss": 1.7083,
      "step": 5280
    },
    {
      "epoch": 1.3804801670146138,
      "grad_norm": 3.283109664916992,
      "learning_rate": 9.427551560021152e-05,
      "loss": 1.7194,
      "step": 5290
    },
    {
      "epoch": 1.383089770354906,
      "grad_norm": 1.7424708604812622,
      "learning_rate": 9.387890005288208e-05,
      "loss": 1.5993,
      "step": 5300
    },
    {
      "epoch": 1.3856993736951984,
      "grad_norm": 2.350409746170044,
      "learning_rate": 9.34822845055526e-05,
      "loss": 1.5723,
      "step": 5310
    },
    {
      "epoch": 1.3883089770354906,
      "grad_norm": 2.0655970573425293,
      "learning_rate": 9.308566895822315e-05,
      "loss": 1.8197,
      "step": 5320
    },
    {
      "epoch": 1.3909185803757829,
      "grad_norm": 1.8948346376419067,
      "learning_rate": 9.268905341089369e-05,
      "loss": 1.5725,
      "step": 5330
    },
    {
      "epoch": 1.3935281837160751,
      "grad_norm": 1.5791082382202148,
      "learning_rate": 9.229243786356424e-05,
      "loss": 1.6135,
      "step": 5340
    },
    {
      "epoch": 1.3961377870563674,
      "grad_norm": 1.2637064456939697,
      "learning_rate": 9.189582231623479e-05,
      "loss": 1.7384,
      "step": 5350
    },
    {
      "epoch": 1.3987473903966596,
      "grad_norm": 2.190358877182007,
      "learning_rate": 9.149920676890533e-05,
      "loss": 1.6741,
      "step": 5360
    },
    {
      "epoch": 1.401356993736952,
      "grad_norm": 1.6856292486190796,
      "learning_rate": 9.110259122157588e-05,
      "loss": 1.5044,
      "step": 5370
    },
    {
      "epoch": 1.4039665970772441,
      "grad_norm": 2.1397294998168945,
      "learning_rate": 9.070597567424643e-05,
      "loss": 1.488,
      "step": 5380
    },
    {
      "epoch": 1.4065762004175366,
      "grad_norm": 1.4703556299209595,
      "learning_rate": 9.030936012691697e-05,
      "loss": 1.7182,
      "step": 5390
    },
    {
      "epoch": 1.4091858037578289,
      "grad_norm": 1.7410334348678589,
      "learning_rate": 8.991274457958751e-05,
      "loss": 1.8839,
      "step": 5400
    },
    {
      "epoch": 1.4091858037578289,
      "eval_loss": 1.6603916883468628,
      "eval_runtime": 2.8502,
      "eval_samples_per_second": 42.103,
      "eval_steps_per_second": 5.263,
      "step": 5400
    },
    {
      "epoch": 1.4117954070981211,
      "grad_norm": 1.4639792442321777,
      "learning_rate": 8.951612903225806e-05,
      "loss": 1.5649,
      "step": 5410
    },
    {
      "epoch": 1.4144050104384134,
      "grad_norm": 1.6891050338745117,
      "learning_rate": 8.911951348492861e-05,
      "loss": 1.7529,
      "step": 5420
    },
    {
      "epoch": 1.4170146137787056,
      "grad_norm": 1.8060519695281982,
      "learning_rate": 8.872289793759915e-05,
      "loss": 1.8709,
      "step": 5430
    },
    {
      "epoch": 1.4196242171189979,
      "grad_norm": 1.9193958044052124,
      "learning_rate": 8.83262823902697e-05,
      "loss": 1.43,
      "step": 5440
    },
    {
      "epoch": 1.4222338204592901,
      "grad_norm": 1.3502463102340698,
      "learning_rate": 8.792966684294023e-05,
      "loss": 1.5271,
      "step": 5450
    },
    {
      "epoch": 1.4248434237995824,
      "grad_norm": 2.0013575553894043,
      "learning_rate": 8.753305129561077e-05,
      "loss": 1.7104,
      "step": 5460
    },
    {
      "epoch": 1.4274530271398747,
      "grad_norm": 1.556505799293518,
      "learning_rate": 8.713643574828132e-05,
      "loss": 1.746,
      "step": 5470
    },
    {
      "epoch": 1.4300626304801671,
      "grad_norm": 1.8938084840774536,
      "learning_rate": 8.673982020095186e-05,
      "loss": 1.6,
      "step": 5480
    },
    {
      "epoch": 1.4326722338204592,
      "grad_norm": 1.8779009580612183,
      "learning_rate": 8.634320465362241e-05,
      "loss": 1.5526,
      "step": 5490
    },
    {
      "epoch": 1.4352818371607516,
      "grad_norm": 1.6132208108901978,
      "learning_rate": 8.594658910629296e-05,
      "loss": 1.7756,
      "step": 5500
    },
    {
      "epoch": 1.437891440501044,
      "grad_norm": 2.683839797973633,
      "learning_rate": 8.55499735589635e-05,
      "loss": 1.3809,
      "step": 5510
    },
    {
      "epoch": 1.4405010438413361,
      "grad_norm": 1.4869180917739868,
      "learning_rate": 8.515335801163405e-05,
      "loss": 1.595,
      "step": 5520
    },
    {
      "epoch": 1.4431106471816284,
      "grad_norm": 1.6857386827468872,
      "learning_rate": 8.47567424643046e-05,
      "loss": 1.7999,
      "step": 5530
    },
    {
      "epoch": 1.4457202505219207,
      "grad_norm": 1.633535385131836,
      "learning_rate": 8.436012691697514e-05,
      "loss": 1.6677,
      "step": 5540
    },
    {
      "epoch": 1.448329853862213,
      "grad_norm": 1.3694945573806763,
      "learning_rate": 8.396351136964568e-05,
      "loss": 1.5256,
      "step": 5550
    },
    {
      "epoch": 1.4509394572025052,
      "grad_norm": 1.5897037982940674,
      "learning_rate": 8.356689582231624e-05,
      "loss": 1.585,
      "step": 5560
    },
    {
      "epoch": 1.4535490605427974,
      "grad_norm": 1.7332544326782227,
      "learning_rate": 8.317028027498678e-05,
      "loss": 1.7782,
      "step": 5570
    },
    {
      "epoch": 1.4561586638830897,
      "grad_norm": 1.4916908740997314,
      "learning_rate": 8.277366472765732e-05,
      "loss": 1.6243,
      "step": 5580
    },
    {
      "epoch": 1.4587682672233822,
      "grad_norm": 1.7389816045761108,
      "learning_rate": 8.237704918032787e-05,
      "loss": 1.6568,
      "step": 5590
    },
    {
      "epoch": 1.4613778705636742,
      "grad_norm": 1.6473877429962158,
      "learning_rate": 8.19804336329984e-05,
      "loss": 1.5894,
      "step": 5600
    },
    {
      "epoch": 1.4613778705636742,
      "eval_loss": 1.655039668083191,
      "eval_runtime": 2.8472,
      "eval_samples_per_second": 42.147,
      "eval_steps_per_second": 5.268,
      "step": 5600
    },
    {
      "epoch": 1.4639874739039667,
      "grad_norm": 2.0873069763183594,
      "learning_rate": 8.158381808566895e-05,
      "loss": 1.608,
      "step": 5610
    },
    {
      "epoch": 1.466597077244259,
      "grad_norm": 1.4633147716522217,
      "learning_rate": 8.118720253833949e-05,
      "loss": 1.6035,
      "step": 5620
    },
    {
      "epoch": 1.4692066805845512,
      "grad_norm": 1.5669447183609009,
      "learning_rate": 8.079058699101004e-05,
      "loss": 1.6118,
      "step": 5630
    },
    {
      "epoch": 1.4718162839248434,
      "grad_norm": 1.807604432106018,
      "learning_rate": 8.039397144368058e-05,
      "loss": 1.5757,
      "step": 5640
    },
    {
      "epoch": 1.4744258872651357,
      "grad_norm": 2.587872266769409,
      "learning_rate": 7.999735589635113e-05,
      "loss": 1.5308,
      "step": 5650
    },
    {
      "epoch": 1.477035490605428,
      "grad_norm": 1.4013994932174683,
      "learning_rate": 7.960074034902167e-05,
      "loss": 1.7442,
      "step": 5660
    },
    {
      "epoch": 1.4796450939457202,
      "grad_norm": 1.598578929901123,
      "learning_rate": 7.920412480169222e-05,
      "loss": 1.614,
      "step": 5670
    },
    {
      "epoch": 1.4822546972860124,
      "grad_norm": 1.44027578830719,
      "learning_rate": 7.880750925436277e-05,
      "loss": 1.646,
      "step": 5680
    },
    {
      "epoch": 1.4848643006263047,
      "grad_norm": 1.6134240627288818,
      "learning_rate": 7.841089370703331e-05,
      "loss": 1.6858,
      "step": 5690
    },
    {
      "epoch": 1.4874739039665972,
      "grad_norm": 1.3167121410369873,
      "learning_rate": 7.801427815970386e-05,
      "loss": 1.7937,
      "step": 5700
    },
    {
      "epoch": 1.4900835073068894,
      "grad_norm": 1.6843068599700928,
      "learning_rate": 7.76176626123744e-05,
      "loss": 1.6898,
      "step": 5710
    },
    {
      "epoch": 1.4926931106471817,
      "grad_norm": 1.428206443786621,
      "learning_rate": 7.722104706504495e-05,
      "loss": 1.6022,
      "step": 5720
    },
    {
      "epoch": 1.495302713987474,
      "grad_norm": 2.1478288173675537,
      "learning_rate": 7.682443151771549e-05,
      "loss": 1.7045,
      "step": 5730
    },
    {
      "epoch": 1.4979123173277662,
      "grad_norm": 1.7024248838424683,
      "learning_rate": 7.642781597038603e-05,
      "loss": 1.4449,
      "step": 5740
    },
    {
      "epoch": 1.5005219206680585,
      "grad_norm": 1.6367298364639282,
      "learning_rate": 7.603120042305657e-05,
      "loss": 1.5148,
      "step": 5750
    },
    {
      "epoch": 1.5031315240083507,
      "grad_norm": 1.9751415252685547,
      "learning_rate": 7.563458487572712e-05,
      "loss": 1.7347,
      "step": 5760
    },
    {
      "epoch": 1.505741127348643,
      "grad_norm": 1.3142956495285034,
      "learning_rate": 7.523796932839766e-05,
      "loss": 1.6671,
      "step": 5770
    },
    {
      "epoch": 1.5083507306889352,
      "grad_norm": 1.823913335800171,
      "learning_rate": 7.484135378106821e-05,
      "loss": 1.6621,
      "step": 5780
    },
    {
      "epoch": 1.5109603340292277,
      "grad_norm": 1.5783547163009644,
      "learning_rate": 7.444473823373875e-05,
      "loss": 1.8344,
      "step": 5790
    },
    {
      "epoch": 1.5135699373695197,
      "grad_norm": 1.9596714973449707,
      "learning_rate": 7.40481226864093e-05,
      "loss": 1.5296,
      "step": 5800
    },
    {
      "epoch": 1.5135699373695197,
      "eval_loss": 1.6553224325180054,
      "eval_runtime": 2.8478,
      "eval_samples_per_second": 42.138,
      "eval_steps_per_second": 5.267,
      "step": 5800
    },
    {
      "epoch": 1.5161795407098122,
      "grad_norm": 2.2633273601531982,
      "learning_rate": 7.365150713907985e-05,
      "loss": 1.7092,
      "step": 5810
    },
    {
      "epoch": 1.5187891440501042,
      "grad_norm": 1.7818280458450317,
      "learning_rate": 7.32548915917504e-05,
      "loss": 1.5264,
      "step": 5820
    },
    {
      "epoch": 1.5213987473903967,
      "grad_norm": 1.375201940536499,
      "learning_rate": 7.285827604442094e-05,
      "loss": 1.5644,
      "step": 5830
    },
    {
      "epoch": 1.524008350730689,
      "grad_norm": 2.2657084465026855,
      "learning_rate": 7.246166049709148e-05,
      "loss": 1.4872,
      "step": 5840
    },
    {
      "epoch": 1.5266179540709812,
      "grad_norm": 1.52940034866333,
      "learning_rate": 7.206504494976202e-05,
      "loss": 1.7937,
      "step": 5850
    },
    {
      "epoch": 1.5292275574112735,
      "grad_norm": 1.4870954751968384,
      "learning_rate": 7.166842940243256e-05,
      "loss": 1.502,
      "step": 5860
    },
    {
      "epoch": 1.5318371607515657,
      "grad_norm": 1.4945193529129028,
      "learning_rate": 7.127181385510312e-05,
      "loss": 1.6996,
      "step": 5870
    },
    {
      "epoch": 1.534446764091858,
      "grad_norm": 1.953335165977478,
      "learning_rate": 7.087519830777366e-05,
      "loss": 1.9291,
      "step": 5880
    },
    {
      "epoch": 1.5370563674321502,
      "grad_norm": 1.5469529628753662,
      "learning_rate": 7.04785827604442e-05,
      "loss": 1.4983,
      "step": 5890
    },
    {
      "epoch": 1.5396659707724427,
      "grad_norm": 1.741896152496338,
      "learning_rate": 7.008196721311476e-05,
      "loss": 1.7643,
      "step": 5900
    },
    {
      "epoch": 1.5422755741127347,
      "grad_norm": 1.4076051712036133,
      "learning_rate": 6.96853516657853e-05,
      "loss": 1.8305,
      "step": 5910
    },
    {
      "epoch": 1.5448851774530272,
      "grad_norm": 1.5420582294464111,
      "learning_rate": 6.928873611845583e-05,
      "loss": 1.6524,
      "step": 5920
    },
    {
      "epoch": 1.5474947807933193,
      "grad_norm": 1.422255039215088,
      "learning_rate": 6.889212057112638e-05,
      "loss": 1.7752,
      "step": 5930
    },
    {
      "epoch": 1.5501043841336117,
      "grad_norm": 1.6382193565368652,
      "learning_rate": 6.849550502379693e-05,
      "loss": 1.6028,
      "step": 5940
    },
    {
      "epoch": 1.552713987473904,
      "grad_norm": 1.3240070343017578,
      "learning_rate": 6.809888947646747e-05,
      "loss": 1.8092,
      "step": 5950
    },
    {
      "epoch": 1.5553235908141962,
      "grad_norm": 1.6966702938079834,
      "learning_rate": 6.770227392913802e-05,
      "loss": 1.6941,
      "step": 5960
    },
    {
      "epoch": 1.5579331941544885,
      "grad_norm": 1.4925510883331299,
      "learning_rate": 6.730565838180856e-05,
      "loss": 1.5758,
      "step": 5970
    },
    {
      "epoch": 1.5605427974947808,
      "grad_norm": 2.49155330657959,
      "learning_rate": 6.69090428344791e-05,
      "loss": 1.7172,
      "step": 5980
    },
    {
      "epoch": 1.5631524008350732,
      "grad_norm": 1.81155526638031,
      "learning_rate": 6.651242728714965e-05,
      "loss": 1.7836,
      "step": 5990
    },
    {
      "epoch": 1.5657620041753653,
      "grad_norm": 1.7654575109481812,
      "learning_rate": 6.611581173982019e-05,
      "loss": 1.4622,
      "step": 6000
    },
    {
      "epoch": 1.5657620041753653,
      "eval_loss": 1.6460366249084473,
      "eval_runtime": 2.8492,
      "eval_samples_per_second": 42.117,
      "eval_steps_per_second": 5.265,
      "step": 6000
    },
    {
      "epoch": 1.5683716075156577,
      "grad_norm": 1.6913968324661255,
      "learning_rate": 6.571919619249073e-05,
      "loss": 1.8148,
      "step": 6010
    },
    {
      "epoch": 1.5709812108559498,
      "grad_norm": 1.9410783052444458,
      "learning_rate": 6.532258064516129e-05,
      "loss": 1.6978,
      "step": 6020
    },
    {
      "epoch": 1.5735908141962422,
      "grad_norm": 1.5046477317810059,
      "learning_rate": 6.492596509783183e-05,
      "loss": 1.2733,
      "step": 6030
    },
    {
      "epoch": 1.5762004175365343,
      "grad_norm": 1.7835785150527954,
      "learning_rate": 6.452934955050237e-05,
      "loss": 1.5319,
      "step": 6040
    },
    {
      "epoch": 1.5788100208768268,
      "grad_norm": 1.7484833002090454,
      "learning_rate": 6.413273400317293e-05,
      "loss": 1.6682,
      "step": 6050
    },
    {
      "epoch": 1.581419624217119,
      "grad_norm": 1.931377649307251,
      "learning_rate": 6.373611845584346e-05,
      "loss": 1.683,
      "step": 6060
    },
    {
      "epoch": 1.5840292275574113,
      "grad_norm": 2.2407639026641846,
      "learning_rate": 6.333950290851401e-05,
      "loss": 1.6088,
      "step": 6070
    },
    {
      "epoch": 1.5866388308977035,
      "grad_norm": 2.126378059387207,
      "learning_rate": 6.294288736118455e-05,
      "loss": 1.5896,
      "step": 6080
    },
    {
      "epoch": 1.5892484342379958,
      "grad_norm": 1.8841735124588013,
      "learning_rate": 6.25462718138551e-05,
      "loss": 1.5255,
      "step": 6090
    },
    {
      "epoch": 1.5918580375782883,
      "grad_norm": 1.5865691900253296,
      "learning_rate": 6.214965626652564e-05,
      "loss": 1.7058,
      "step": 6100
    },
    {
      "epoch": 1.5944676409185803,
      "grad_norm": 1.9149963855743408,
      "learning_rate": 6.175304071919619e-05,
      "loss": 1.8083,
      "step": 6110
    },
    {
      "epoch": 1.5970772442588728,
      "grad_norm": 2.061724901199341,
      "learning_rate": 6.135642517186673e-05,
      "loss": 1.3045,
      "step": 6120
    },
    {
      "epoch": 1.5996868475991648,
      "grad_norm": 1.6169699430465698,
      "learning_rate": 6.095980962453727e-05,
      "loss": 1.6026,
      "step": 6130
    },
    {
      "epoch": 1.6022964509394573,
      "grad_norm": 1.9341410398483276,
      "learning_rate": 6.056319407720782e-05,
      "loss": 1.5403,
      "step": 6140
    },
    {
      "epoch": 1.6049060542797495,
      "grad_norm": 1.5453903675079346,
      "learning_rate": 6.016657852987837e-05,
      "loss": 1.8372,
      "step": 6150
    },
    {
      "epoch": 1.6075156576200418,
      "grad_norm": 1.4898878335952759,
      "learning_rate": 5.976996298254891e-05,
      "loss": 1.6838,
      "step": 6160
    },
    {
      "epoch": 1.610125260960334,
      "grad_norm": 2.095289945602417,
      "learning_rate": 5.937334743521946e-05,
      "loss": 1.3268,
      "step": 6170
    },
    {
      "epoch": 1.6127348643006263,
      "grad_norm": 1.4587938785552979,
      "learning_rate": 5.897673188789e-05,
      "loss": 1.5919,
      "step": 6180
    },
    {
      "epoch": 1.6153444676409185,
      "grad_norm": 1.2631559371948242,
      "learning_rate": 5.858011634056055e-05,
      "loss": 1.574,
      "step": 6190
    },
    {
      "epoch": 1.6179540709812108,
      "grad_norm": 1.7030481100082397,
      "learning_rate": 5.8183500793231084e-05,
      "loss": 1.7105,
      "step": 6200
    },
    {
      "epoch": 1.6179540709812108,
      "eval_loss": 1.644006371498108,
      "eval_runtime": 2.8474,
      "eval_samples_per_second": 42.144,
      "eval_steps_per_second": 5.268,
      "step": 6200
    },
    {
      "epoch": 1.6205636743215033,
      "grad_norm": 1.410660982131958,
      "learning_rate": 5.778688524590163e-05,
      "loss": 1.7051,
      "step": 6210
    },
    {
      "epoch": 1.6231732776617953,
      "grad_norm": 1.9647530317306519,
      "learning_rate": 5.7390269698572175e-05,
      "loss": 1.5209,
      "step": 6220
    },
    {
      "epoch": 1.6257828810020878,
      "grad_norm": 1.8166567087173462,
      "learning_rate": 5.6993654151242724e-05,
      "loss": 1.6538,
      "step": 6230
    },
    {
      "epoch": 1.6283924843423798,
      "grad_norm": 2.021653175354004,
      "learning_rate": 5.659703860391327e-05,
      "loss": 1.6917,
      "step": 6240
    },
    {
      "epoch": 1.6310020876826723,
      "grad_norm": 1.7098634243011475,
      "learning_rate": 5.6200423056583815e-05,
      "loss": 1.7737,
      "step": 6250
    },
    {
      "epoch": 1.6336116910229646,
      "grad_norm": 1.680163025856018,
      "learning_rate": 5.580380750925436e-05,
      "loss": 1.7062,
      "step": 6260
    },
    {
      "epoch": 1.6362212943632568,
      "grad_norm": 1.4291763305664062,
      "learning_rate": 5.54071919619249e-05,
      "loss": 1.6703,
      "step": 6270
    },
    {
      "epoch": 1.638830897703549,
      "grad_norm": 2.2659120559692383,
      "learning_rate": 5.501057641459545e-05,
      "loss": 1.6198,
      "step": 6280
    },
    {
      "epoch": 1.6414405010438413,
      "grad_norm": 1.730865478515625,
      "learning_rate": 5.461396086726599e-05,
      "loss": 1.7407,
      "step": 6290
    },
    {
      "epoch": 1.6440501043841336,
      "grad_norm": 2.721287488937378,
      "learning_rate": 5.421734531993654e-05,
      "loss": 1.6492,
      "step": 6300
    },
    {
      "epoch": 1.6466597077244258,
      "grad_norm": 1.7581077814102173,
      "learning_rate": 5.382072977260708e-05,
      "loss": 1.5836,
      "step": 6310
    },
    {
      "epoch": 1.6492693110647183,
      "grad_norm": 2.124164581298828,
      "learning_rate": 5.342411422527763e-05,
      "loss": 1.6752,
      "step": 6320
    },
    {
      "epoch": 1.6518789144050103,
      "grad_norm": 1.6999276876449585,
      "learning_rate": 5.302749867794818e-05,
      "loss": 1.5893,
      "step": 6330
    },
    {
      "epoch": 1.6544885177453028,
      "grad_norm": 1.4534226655960083,
      "learning_rate": 5.263088313061871e-05,
      "loss": 1.6479,
      "step": 6340
    },
    {
      "epoch": 1.6570981210855948,
      "grad_norm": 1.451873779296875,
      "learning_rate": 5.2234267583289255e-05,
      "loss": 1.4606,
      "step": 6350
    },
    {
      "epoch": 1.6597077244258873,
      "grad_norm": 2.0450119972229004,
      "learning_rate": 5.18376520359598e-05,
      "loss": 1.4532,
      "step": 6360
    },
    {
      "epoch": 1.6623173277661796,
      "grad_norm": 1.7891967296600342,
      "learning_rate": 5.144103648863035e-05,
      "loss": 1.5982,
      "step": 6370
    },
    {
      "epoch": 1.6649269311064718,
      "grad_norm": 1.9380769729614258,
      "learning_rate": 5.1044420941300894e-05,
      "loss": 1.5378,
      "step": 6380
    },
    {
      "epoch": 1.667536534446764,
      "grad_norm": 1.4143611192703247,
      "learning_rate": 5.064780539397144e-05,
      "loss": 1.7335,
      "step": 6390
    },
    {
      "epoch": 1.6701461377870563,
      "grad_norm": 2.370875835418701,
      "learning_rate": 5.0251189846641985e-05,
      "loss": 1.5643,
      "step": 6400
    },
    {
      "epoch": 1.6701461377870563,
      "eval_loss": 1.636827826499939,
      "eval_runtime": 2.8493,
      "eval_samples_per_second": 42.115,
      "eval_steps_per_second": 5.264,
      "step": 6400
    },
    {
      "epoch": 1.6727557411273486,
      "grad_norm": 1.2684621810913086,
      "learning_rate": 4.985457429931253e-05,
      "loss": 1.5881,
      "step": 6410
    },
    {
      "epoch": 1.6753653444676408,
      "grad_norm": 1.4964169263839722,
      "learning_rate": 4.945795875198307e-05,
      "loss": 1.7219,
      "step": 6420
    },
    {
      "epoch": 1.6779749478079333,
      "grad_norm": 1.8973878622055054,
      "learning_rate": 4.906134320465362e-05,
      "loss": 1.6646,
      "step": 6430
    },
    {
      "epoch": 1.6805845511482254,
      "grad_norm": 1.513353943824768,
      "learning_rate": 4.866472765732416e-05,
      "loss": 1.6284,
      "step": 6440
    },
    {
      "epoch": 1.6831941544885178,
      "grad_norm": 2.140275239944458,
      "learning_rate": 4.826811210999471e-05,
      "loss": 1.6245,
      "step": 6450
    },
    {
      "epoch": 1.6858037578288099,
      "grad_norm": 2.109795570373535,
      "learning_rate": 4.787149656266526e-05,
      "loss": 1.688,
      "step": 6460
    },
    {
      "epoch": 1.6884133611691023,
      "grad_norm": 1.4019842147827148,
      "learning_rate": 4.74748810153358e-05,
      "loss": 1.7947,
      "step": 6470
    },
    {
      "epoch": 1.6910229645093946,
      "grad_norm": 1.5738722085952759,
      "learning_rate": 4.707826546800634e-05,
      "loss": 1.8907,
      "step": 6480
    },
    {
      "epoch": 1.6936325678496869,
      "grad_norm": 1.5997469425201416,
      "learning_rate": 4.668164992067688e-05,
      "loss": 1.6625,
      "step": 6490
    },
    {
      "epoch": 1.696242171189979,
      "grad_norm": 1.9850696325302124,
      "learning_rate": 4.632469592808038e-05,
      "loss": 1.7776,
      "step": 6500
    },
    {
      "epoch": 1.6988517745302714,
      "grad_norm": 1.5862219333648682,
      "learning_rate": 4.5928080380750915e-05,
      "loss": 1.8172,
      "step": 6510
    },
    {
      "epoch": 1.7014613778705638,
      "grad_norm": 2.074723720550537,
      "learning_rate": 4.5531464833421464e-05,
      "loss": 1.4557,
      "step": 6520
    },
    {
      "epoch": 1.7040709812108559,
      "grad_norm": 1.5281543731689453,
      "learning_rate": 4.5134849286092006e-05,
      "loss": 1.5703,
      "step": 6530
    },
    {
      "epoch": 1.7066805845511483,
      "grad_norm": 1.6731452941894531,
      "learning_rate": 4.4738233738762555e-05,
      "loss": 1.7151,
      "step": 6540
    },
    {
      "epoch": 1.7092901878914404,
      "grad_norm": 1.506649374961853,
      "learning_rate": 4.4341618191433104e-05,
      "loss": 1.637,
      "step": 6550
    },
    {
      "epoch": 1.7118997912317329,
      "grad_norm": 1.4602514505386353,
      "learning_rate": 4.3945002644103646e-05,
      "loss": 1.7051,
      "step": 6560
    },
    {
      "epoch": 1.714509394572025,
      "grad_norm": 1.858141303062439,
      "learning_rate": 4.3548387096774194e-05,
      "loss": 1.5141,
      "step": 6570
    },
    {
      "epoch": 1.7171189979123174,
      "grad_norm": 1.7815508842468262,
      "learning_rate": 4.3151771549444736e-05,
      "loss": 1.8364,
      "step": 6580
    },
    {
      "epoch": 1.7197286012526096,
      "grad_norm": 1.66059410572052,
      "learning_rate": 4.275515600211528e-05,
      "loss": 1.7113,
      "step": 6590
    },
    {
      "epoch": 1.7223382045929019,
      "grad_norm": 1.7026296854019165,
      "learning_rate": 4.235854045478582e-05,
      "loss": 1.7251,
      "step": 6600
    },
    {
      "epoch": 1.7223382045929019,
      "eval_loss": 1.6312311887741089,
      "eval_runtime": 2.8497,
      "eval_samples_per_second": 42.11,
      "eval_steps_per_second": 5.264,
      "step": 6600
    },
    {
      "epoch": 1.7249478079331941,
      "grad_norm": 1.7852190732955933,
      "learning_rate": 4.196192490745637e-05,
      "loss": 1.615,
      "step": 6610
    },
    {
      "epoch": 1.7275574112734864,
      "grad_norm": 1.9450733661651611,
      "learning_rate": 4.156530936012691e-05,
      "loss": 2.0545,
      "step": 6620
    },
    {
      "epoch": 1.7301670146137789,
      "grad_norm": 1.8729255199432373,
      "learning_rate": 4.116869381279746e-05,
      "loss": 1.7009,
      "step": 6630
    },
    {
      "epoch": 1.732776617954071,
      "grad_norm": 2.2752134799957275,
      "learning_rate": 4.077207826546801e-05,
      "loss": 1.6432,
      "step": 6640
    },
    {
      "epoch": 1.7353862212943634,
      "grad_norm": 1.6837414503097534,
      "learning_rate": 4.037546271813855e-05,
      "loss": 2.1905,
      "step": 6650
    },
    {
      "epoch": 1.7379958246346554,
      "grad_norm": 1.383906364440918,
      "learning_rate": 3.997884717080909e-05,
      "loss": 1.7252,
      "step": 6660
    },
    {
      "epoch": 1.7406054279749479,
      "grad_norm": 1.3302093744277954,
      "learning_rate": 3.9582231623479634e-05,
      "loss": 1.6956,
      "step": 6670
    },
    {
      "epoch": 1.7432150313152401,
      "grad_norm": 1.651640772819519,
      "learning_rate": 3.918561607615018e-05,
      "loss": 1.7404,
      "step": 6680
    },
    {
      "epoch": 1.7458246346555324,
      "grad_norm": 2.313025712966919,
      "learning_rate": 3.8789000528820725e-05,
      "loss": 1.6499,
      "step": 6690
    },
    {
      "epoch": 1.7484342379958246,
      "grad_norm": 2.2252871990203857,
      "learning_rate": 3.8392384981491274e-05,
      "loss": 1.6763,
      "step": 6700
    },
    {
      "epoch": 1.751043841336117,
      "grad_norm": 1.4136580228805542,
      "learning_rate": 3.7995769434161816e-05,
      "loss": 1.5923,
      "step": 6710
    },
    {
      "epoch": 1.7536534446764092,
      "grad_norm": 1.3846683502197266,
      "learning_rate": 3.7599153886832365e-05,
      "loss": 1.8095,
      "step": 6720
    },
    {
      "epoch": 1.7562630480167014,
      "grad_norm": 2.4024715423583984,
      "learning_rate": 3.7202538339502907e-05,
      "loss": 1.8648,
      "step": 6730
    },
    {
      "epoch": 1.7588726513569939,
      "grad_norm": 1.8471907377243042,
      "learning_rate": 3.6805922792173455e-05,
      "loss": 1.7437,
      "step": 6740
    },
    {
      "epoch": 1.761482254697286,
      "grad_norm": 1.5670369863510132,
      "learning_rate": 3.640930724484399e-05,
      "loss": 1.7219,
      "step": 6750
    },
    {
      "epoch": 1.7640918580375784,
      "grad_norm": 1.6139347553253174,
      "learning_rate": 3.601269169751454e-05,
      "loss": 1.5127,
      "step": 6760
    },
    {
      "epoch": 1.7667014613778704,
      "grad_norm": 1.8054085969924927,
      "learning_rate": 3.561607615018509e-05,
      "loss": 1.6964,
      "step": 6770
    },
    {
      "epoch": 1.769311064718163,
      "grad_norm": 2.3863234519958496,
      "learning_rate": 3.521946060285563e-05,
      "loss": 1.7492,
      "step": 6780
    },
    {
      "epoch": 1.7719206680584552,
      "grad_norm": 1.9194681644439697,
      "learning_rate": 3.482284505552617e-05,
      "loss": 1.6963,
      "step": 6790
    },
    {
      "epoch": 1.7745302713987474,
      "grad_norm": 2.290347099304199,
      "learning_rate": 3.442622950819672e-05,
      "loss": 1.694,
      "step": 6800
    },
    {
      "epoch": 1.7745302713987474,
      "eval_loss": 1.6296744346618652,
      "eval_runtime": 2.8521,
      "eval_samples_per_second": 42.074,
      "eval_steps_per_second": 5.259,
      "step": 6800
    },
    {
      "epoch": 1.7771398747390397,
      "grad_norm": 1.5542900562286377,
      "learning_rate": 3.402961396086726e-05,
      "loss": 1.3133,
      "step": 6810
    },
    {
      "epoch": 1.779749478079332,
      "grad_norm": 1.8013032674789429,
      "learning_rate": 3.3632998413537805e-05,
      "loss": 1.5715,
      "step": 6820
    },
    {
      "epoch": 1.7823590814196242,
      "grad_norm": 2.0213205814361572,
      "learning_rate": 3.3236382866208353e-05,
      "loss": 1.6543,
      "step": 6830
    },
    {
      "epoch": 1.7849686847599164,
      "grad_norm": 1.9073768854141235,
      "learning_rate": 3.2839767318878895e-05,
      "loss": 1.5398,
      "step": 6840
    },
    {
      "epoch": 1.787578288100209,
      "grad_norm": 1.6450426578521729,
      "learning_rate": 3.244315177154944e-05,
      "loss": 1.6515,
      "step": 6850
    },
    {
      "epoch": 1.790187891440501,
      "grad_norm": 1.649209976196289,
      "learning_rate": 3.2046536224219986e-05,
      "loss": 1.6867,
      "step": 6860
    },
    {
      "epoch": 1.7927974947807934,
      "grad_norm": 1.6292222738265991,
      "learning_rate": 3.1649920676890535e-05,
      "loss": 1.7406,
      "step": 6870
    },
    {
      "epoch": 1.7954070981210855,
      "grad_norm": 1.7607454061508179,
      "learning_rate": 3.125330512956108e-05,
      "loss": 1.85,
      "step": 6880
    },
    {
      "epoch": 1.798016701461378,
      "grad_norm": 1.6598848104476929,
      "learning_rate": 3.085668958223162e-05,
      "loss": 1.5092,
      "step": 6890
    },
    {
      "epoch": 1.8006263048016702,
      "grad_norm": 1.895358920097351,
      "learning_rate": 3.0460074034902164e-05,
      "loss": 1.4894,
      "step": 6900
    },
    {
      "epoch": 1.8032359081419624,
      "grad_norm": 2.391597270965576,
      "learning_rate": 3.0063458487572713e-05,
      "loss": 1.3307,
      "step": 6910
    },
    {
      "epoch": 1.8058455114822547,
      "grad_norm": 1.4981025457382202,
      "learning_rate": 2.966684294024325e-05,
      "loss": 1.6525,
      "step": 6920
    },
    {
      "epoch": 1.808455114822547,
      "grad_norm": 1.830235242843628,
      "learning_rate": 2.92702273929138e-05,
      "loss": 1.705,
      "step": 6930
    },
    {
      "epoch": 1.8110647181628392,
      "grad_norm": 2.8727478981018066,
      "learning_rate": 2.8873611845584346e-05,
      "loss": 1.4957,
      "step": 6940
    },
    {
      "epoch": 1.8136743215031315,
      "grad_norm": 1.843900203704834,
      "learning_rate": 2.847699629825489e-05,
      "loss": 1.4911,
      "step": 6950
    },
    {
      "epoch": 1.816283924843424,
      "grad_norm": 1.8602992296218872,
      "learning_rate": 2.8080380750925433e-05,
      "loss": 1.7271,
      "step": 6960
    },
    {
      "epoch": 1.818893528183716,
      "grad_norm": 2.1189939975738525,
      "learning_rate": 2.768376520359598e-05,
      "loss": 1.6921,
      "step": 6970
    },
    {
      "epoch": 1.8215031315240084,
      "grad_norm": 1.4196932315826416,
      "learning_rate": 2.7287149656266524e-05,
      "loss": 1.5669,
      "step": 6980
    },
    {
      "epoch": 1.8241127348643005,
      "grad_norm": 1.714443325996399,
      "learning_rate": 2.6890534108937066e-05,
      "loss": 1.6525,
      "step": 6990
    },
    {
      "epoch": 1.826722338204593,
      "grad_norm": 1.621793270111084,
      "learning_rate": 2.649391856160761e-05,
      "loss": 1.5748,
      "step": 7000
    },
    {
      "epoch": 1.826722338204593,
      "eval_loss": 1.6268402338027954,
      "eval_runtime": 2.8496,
      "eval_samples_per_second": 42.11,
      "eval_steps_per_second": 5.264,
      "step": 7000
    },
    {
      "epoch": 1.8293319415448852,
      "grad_norm": 2.329031229019165,
      "learning_rate": 2.6097303014278156e-05,
      "loss": 1.567,
      "step": 7010
    },
    {
      "epoch": 1.8319415448851775,
      "grad_norm": 1.3696672916412354,
      "learning_rate": 2.5700687466948705e-05,
      "loss": 1.5591,
      "step": 7020
    },
    {
      "epoch": 1.8345511482254697,
      "grad_norm": 1.329911231994629,
      "learning_rate": 2.5304071919619244e-05,
      "loss": 1.616,
      "step": 7030
    },
    {
      "epoch": 1.837160751565762,
      "grad_norm": 2.0282647609710693,
      "learning_rate": 2.4907456372289793e-05,
      "loss": 1.8107,
      "step": 7040
    },
    {
      "epoch": 1.8397703549060542,
      "grad_norm": 2.067761182785034,
      "learning_rate": 2.4510840824960338e-05,
      "loss": 1.5392,
      "step": 7050
    },
    {
      "epoch": 1.8423799582463465,
      "grad_norm": 1.4018059968948364,
      "learning_rate": 2.4114225277630883e-05,
      "loss": 1.5221,
      "step": 7060
    },
    {
      "epoch": 1.844989561586639,
      "grad_norm": 1.6440134048461914,
      "learning_rate": 2.3717609730301425e-05,
      "loss": 1.5946,
      "step": 7070
    },
    {
      "epoch": 1.847599164926931,
      "grad_norm": 1.6052122116088867,
      "learning_rate": 2.332099418297197e-05,
      "loss": 1.6469,
      "step": 7080
    },
    {
      "epoch": 1.8502087682672235,
      "grad_norm": 1.5266761779785156,
      "learning_rate": 2.2924378635642516e-05,
      "loss": 1.5963,
      "step": 7090
    },
    {
      "epoch": 1.8528183716075155,
      "grad_norm": 1.3144038915634155,
      "learning_rate": 2.2527763088313058e-05,
      "loss": 1.6919,
      "step": 7100
    },
    {
      "epoch": 1.855427974947808,
      "grad_norm": 2.0602288246154785,
      "learning_rate": 2.2131147540983603e-05,
      "loss": 1.6436,
      "step": 7110
    },
    {
      "epoch": 1.8580375782881002,
      "grad_norm": 1.5732953548431396,
      "learning_rate": 2.173453199365415e-05,
      "loss": 1.8161,
      "step": 7120
    },
    {
      "epoch": 1.8606471816283925,
      "grad_norm": 2.151097536087036,
      "learning_rate": 2.1337916446324697e-05,
      "loss": 1.6566,
      "step": 7130
    },
    {
      "epoch": 1.8632567849686847,
      "grad_norm": 2.4587790966033936,
      "learning_rate": 2.094130089899524e-05,
      "loss": 1.7093,
      "step": 7140
    },
    {
      "epoch": 1.865866388308977,
      "grad_norm": 1.6820837259292603,
      "learning_rate": 2.0544685351665785e-05,
      "loss": 1.4926,
      "step": 7150
    },
    {
      "epoch": 1.8684759916492695,
      "grad_norm": 1.7241460084915161,
      "learning_rate": 2.014806980433633e-05,
      "loss": 1.6544,
      "step": 7160
    },
    {
      "epoch": 1.8710855949895615,
      "grad_norm": 2.031897783279419,
      "learning_rate": 1.9751454257006872e-05,
      "loss": 1.406,
      "step": 7170
    },
    {
      "epoch": 1.873695198329854,
      "grad_norm": 1.7324453592300415,
      "learning_rate": 1.9354838709677417e-05,
      "loss": 1.7605,
      "step": 7180
    },
    {
      "epoch": 1.876304801670146,
      "grad_norm": 2.051406145095825,
      "learning_rate": 1.8958223162347963e-05,
      "loss": 1.6557,
      "step": 7190
    },
    {
      "epoch": 1.8789144050104385,
      "grad_norm": 1.8496246337890625,
      "learning_rate": 1.8561607615018508e-05,
      "loss": 1.6517,
      "step": 7200
    },
    {
      "epoch": 1.8789144050104385,
      "eval_loss": 1.6237057447433472,
      "eval_runtime": 2.8478,
      "eval_samples_per_second": 42.138,
      "eval_steps_per_second": 5.267,
      "step": 7200
    },
    {
      "epoch": 1.8815240083507305,
      "grad_norm": 1.9173222780227661,
      "learning_rate": 1.8164992067689054e-05,
      "loss": 1.6275,
      "step": 7210
    },
    {
      "epoch": 1.884133611691023,
      "grad_norm": 1.3390052318572998,
      "learning_rate": 1.7768376520359596e-05,
      "loss": 1.7771,
      "step": 7220
    },
    {
      "epoch": 1.8867432150313153,
      "grad_norm": 2.4498584270477295,
      "learning_rate": 1.737176097303014e-05,
      "loss": 1.7125,
      "step": 7230
    },
    {
      "epoch": 1.8893528183716075,
      "grad_norm": 1.8754181861877441,
      "learning_rate": 1.6975145425700686e-05,
      "loss": 1.6832,
      "step": 7240
    },
    {
      "epoch": 1.8919624217118998,
      "grad_norm": 1.666463017463684,
      "learning_rate": 1.657852987837123e-05,
      "loss": 1.4992,
      "step": 7250
    },
    {
      "epoch": 1.894572025052192,
      "grad_norm": 1.4891501665115356,
      "learning_rate": 1.6181914331041777e-05,
      "loss": 1.6537,
      "step": 7260
    },
    {
      "epoch": 1.8971816283924845,
      "grad_norm": 1.2568148374557495,
      "learning_rate": 1.578529878371232e-05,
      "loss": 1.532,
      "step": 7270
    },
    {
      "epoch": 1.8997912317327765,
      "grad_norm": 1.7019641399383545,
      "learning_rate": 1.5388683236382864e-05,
      "loss": 1.5786,
      "step": 7280
    },
    {
      "epoch": 1.902400835073069,
      "grad_norm": 1.5850622653961182,
      "learning_rate": 1.499206768905341e-05,
      "loss": 1.4059,
      "step": 7290
    },
    {
      "epoch": 1.905010438413361,
      "grad_norm": 1.778512716293335,
      "learning_rate": 1.4595452141723955e-05,
      "loss": 1.4403,
      "step": 7300
    },
    {
      "epoch": 1.9076200417536535,
      "grad_norm": 1.8619412183761597,
      "learning_rate": 1.4198836594394499e-05,
      "loss": 1.5968,
      "step": 7310
    },
    {
      "epoch": 1.9102296450939458,
      "grad_norm": 1.606823444366455,
      "learning_rate": 1.3802221047065042e-05,
      "loss": 1.3256,
      "step": 7320
    },
    {
      "epoch": 1.912839248434238,
      "grad_norm": 1.811509132385254,
      "learning_rate": 1.340560549973559e-05,
      "loss": 1.7986,
      "step": 7330
    },
    {
      "epoch": 1.9154488517745303,
      "grad_norm": 2.094745397567749,
      "learning_rate": 1.3008989952406133e-05,
      "loss": 1.8748,
      "step": 7340
    },
    {
      "epoch": 1.9180584551148225,
      "grad_norm": 2.597731351852417,
      "learning_rate": 1.2612374405076678e-05,
      "loss": 1.4991,
      "step": 7350
    },
    {
      "epoch": 1.9206680584551148,
      "grad_norm": 1.8110443353652954,
      "learning_rate": 1.2215758857747222e-05,
      "loss": 1.5505,
      "step": 7360
    },
    {
      "epoch": 1.923277661795407,
      "grad_norm": 1.9352980852127075,
      "learning_rate": 1.1819143310417767e-05,
      "loss": 1.8735,
      "step": 7370
    },
    {
      "epoch": 1.9258872651356995,
      "grad_norm": 1.6160144805908203,
      "learning_rate": 1.1422527763088313e-05,
      "loss": 1.5709,
      "step": 7380
    },
    {
      "epoch": 1.9284968684759916,
      "grad_norm": 1.8110623359680176,
      "learning_rate": 1.1025912215758857e-05,
      "loss": 1.9422,
      "step": 7390
    },
    {
      "epoch": 1.931106471816284,
      "grad_norm": 2.408928871154785,
      "learning_rate": 1.0629296668429402e-05,
      "loss": 1.7436,
      "step": 7400
    },
    {
      "epoch": 1.931106471816284,
      "eval_loss": 1.6207956075668335,
      "eval_runtime": 2.8433,
      "eval_samples_per_second": 42.205,
      "eval_steps_per_second": 5.276,
      "step": 7400
    },
    {
      "epoch": 1.933716075156576,
      "grad_norm": 1.5539515018463135,
      "learning_rate": 1.0232681121099946e-05,
      "loss": 1.7843,
      "step": 7410
    },
    {
      "epoch": 1.9363256784968685,
      "grad_norm": 1.7436295747756958,
      "learning_rate": 9.836065573770491e-06,
      "loss": 1.4626,
      "step": 7420
    },
    {
      "epoch": 1.9389352818371608,
      "grad_norm": 1.484471082687378,
      "learning_rate": 9.439450026441035e-06,
      "loss": 1.5108,
      "step": 7430
    },
    {
      "epoch": 1.941544885177453,
      "grad_norm": 1.7603405714035034,
      "learning_rate": 9.04283447911158e-06,
      "loss": 1.5805,
      "step": 7440
    },
    {
      "epoch": 1.9441544885177453,
      "grad_norm": 1.8131890296936035,
      "learning_rate": 8.646218931782125e-06,
      "loss": 1.5559,
      "step": 7450
    },
    {
      "epoch": 1.9467640918580376,
      "grad_norm": 1.7884465456008911,
      "learning_rate": 8.249603384452669e-06,
      "loss": 1.6049,
      "step": 7460
    },
    {
      "epoch": 1.9493736951983298,
      "grad_norm": 2.1276330947875977,
      "learning_rate": 7.852987837123214e-06,
      "loss": 1.7407,
      "step": 7470
    },
    {
      "epoch": 1.951983298538622,
      "grad_norm": 1.7193814516067505,
      "learning_rate": 7.45637228979376e-06,
      "loss": 1.6269,
      "step": 7480
    },
    {
      "epoch": 1.9545929018789145,
      "grad_norm": 1.546710729598999,
      "learning_rate": 7.059756742464304e-06,
      "loss": 1.5986,
      "step": 7490
    },
    {
      "epoch": 1.9572025052192066,
      "grad_norm": 3.805443286895752,
      "learning_rate": 6.702802749867795e-06,
      "loss": 1.7311,
      "step": 7500
    },
    {
      "epoch": 1.959812108559499,
      "grad_norm": 1.814503788948059,
      "learning_rate": 6.306187202538339e-06,
      "loss": 1.4719,
      "step": 7510
    },
    {
      "epoch": 1.962421711899791,
      "grad_norm": 1.5209708213806152,
      "learning_rate": 5.909571655208884e-06,
      "loss": 1.4123,
      "step": 7520
    },
    {
      "epoch": 1.9650313152400836,
      "grad_norm": 2.0025110244750977,
      "learning_rate": 5.512956107879428e-06,
      "loss": 1.7594,
      "step": 7530
    },
    {
      "epoch": 1.9676409185803758,
      "grad_norm": 2.128732681274414,
      "learning_rate": 5.116340560549973e-06,
      "loss": 1.6761,
      "step": 7540
    },
    {
      "epoch": 1.970250521920668,
      "grad_norm": 1.5634050369262695,
      "learning_rate": 4.719725013220517e-06,
      "loss": 1.5698,
      "step": 7550
    },
    {
      "epoch": 1.9728601252609603,
      "grad_norm": 2.539105176925659,
      "learning_rate": 4.323109465891063e-06,
      "loss": 1.7754,
      "step": 7560
    },
    {
      "epoch": 1.9754697286012526,
      "grad_norm": 1.6049048900604248,
      "learning_rate": 3.926493918561607e-06,
      "loss": 1.8225,
      "step": 7570
    },
    {
      "epoch": 1.9780793319415448,
      "grad_norm": 2.039774179458618,
      "learning_rate": 3.529878371232152e-06,
      "loss": 1.7653,
      "step": 7580
    },
    {
      "epoch": 1.980688935281837,
      "grad_norm": 1.72026789188385,
      "learning_rate": 3.1332628239026966e-06,
      "loss": 1.5765,
      "step": 7590
    },
    {
      "epoch": 1.9832985386221296,
      "grad_norm": 1.746746301651001,
      "learning_rate": 2.7366472765732416e-06,
      "loss": 1.6584,
      "step": 7600
    },
    {
      "epoch": 1.9832985386221296,
      "eval_loss": 1.6197333335876465,
      "eval_runtime": 2.8434,
      "eval_samples_per_second": 42.203,
      "eval_steps_per_second": 5.275,
      "step": 7600
    },
    {
      "epoch": 1.9859081419624216,
      "grad_norm": 2.3084449768066406,
      "learning_rate": 2.340031729243786e-06,
      "loss": 1.7786,
      "step": 7610
    },
    {
      "epoch": 1.988517745302714,
      "grad_norm": 2.131134271621704,
      "learning_rate": 1.9434161819143306e-06,
      "loss": 1.9166,
      "step": 7620
    },
    {
      "epoch": 1.9911273486430061,
      "grad_norm": 1.5355710983276367,
      "learning_rate": 1.5468006345848758e-06,
      "loss": 1.8229,
      "step": 7630
    },
    {
      "epoch": 1.9937369519832986,
      "grad_norm": 1.626690149307251,
      "learning_rate": 1.1501850872554205e-06,
      "loss": 1.6012,
      "step": 7640
    },
    {
      "epoch": 1.9963465553235908,
      "grad_norm": 2.179940700531006,
      "learning_rate": 7.535695399259651e-07,
      "loss": 1.7426,
      "step": 7650
    },
    {
      "epoch": 1.998956158663883,
      "grad_norm": 1.8051577806472778,
      "learning_rate": 3.569539925965098e-07,
      "loss": 1.6243,
      "step": 7660
    }
  ],
  "logging_steps": 10,
  "max_steps": 7664,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.495634560512164e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
